<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="网络编程实战">
<meta property="og:type" content="article">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="https://nannaer.github.io/2023/04/24/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="网络编程实战">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/20.png">
<meta property="og:image" content="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/21.png">
<meta property="og:image" content="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/28.png">
<meta property="og:image" content="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/22.png">
<meta property="og:image" content="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/23.png">
<meta property="og:image" content="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/24.png">
<meta property="og:image" content="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/25.png">
<meta property="og:image" content="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/26.png">
<meta property="og:image" content="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/27.png">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/12979420-f56600a05f27b88a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/741/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/12979420-702d5971c057c06e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/865/format/webp">
<meta property="og:image" content="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/29.png">
<meta property="og:image" content="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/30.png">
<meta property="og:image" content="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/30.png">
<meta property="og:image" content="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/31.png">
<meta property="og:image" content="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/32.png">
<meta property="og:image" content="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/33.png">
<meta property="og:image" content="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/34.png">
<meta property="og:image" content="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/35.png">
<meta property="og:image" content="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/36.png">
<meta property="og:image" content="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/37.png">
<meta property="og:image" content="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/38.png">
<meta property="og:image" content="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/39.png">
<meta property="article:published_time" content="2023-04-24T08:53:24.518Z">
<meta property="article:modified_time" content="2023-04-27T11:53:17.566Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/20.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 5.4.2"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://nannaer.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-网络编程实战" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/04/24/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/" class="article-date">
  <time datetime="2023-04-24T08:53:24.518Z" itemprop="datePublished">2023-04-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="网络编程实战"><a href="#网络编程实战" class="headerlink" title="网络编程实战"></a>网络编程实战</h1><span id="more"></span>

<p><u><em><strong>仅用于个人学习，侵删</strong></em></u></p>
<h2 id="1-开篇词-学好网络编程，需要掌握哪些核心问题？"><a href="#1-开篇词-学好网络编程，需要掌握哪些核心问题？" class="headerlink" title="1 开篇词 | 学好网络编程，需要掌握哪些核心问题？"></a>1 <strong>开篇词</strong> <strong>|</strong> <strong>学好网络编程，需要掌握哪些核心问题？</strong></h2><p>如果我问你一些关于网络编程方面的问题，你会怎样回答呢？</p>
<p>大家经常说的四层、七层，分别指的是什么？</p>
<p>TCP 三次握手是什么，TIME_WAIT 是怎么发生的？CLOSE_WAIT 又是什么状态？</p>
<p>Linux 下的 <code>epoll</code> 解决的是什么问题？如何使用 <code>epoll</code> 写出高性能的网络程序？</p>
<p>什么是网络事件驱动模型？Reactor 模式又是什么？</p>
<p>这些问题看似简单，但想做到完全理解可并不容易。很多人可能停留在“是这样”的状态，对于“为什么”缺乏深入和了解。</p>
<p>我在学网络编程的时候，也面临着这种窘境。我发现很多情况下，我们都希望尽可能详尽地学习网络编程，面面俱到，但奈何头绪太多，对于初学者来说很容易深陷其中，钻牛角尖，也就难以去理清脉络了。</p>
<p>这样导致的后果就是过分关注知识点本身，片面地斩断了它们与实际工作的联系。比如流量控制和拥塞控制这一部分的内容。我记得我在学这部分知识的时候，纯粹是把这些当做考试的知识点来学习，很难将书本的知识和实际经验，尤其是和代码结合起来进行理解。为什么会有这些算法，它们究竟解决了哪些问题？这些问题搞不懂，看似无伤大雅，其实已经或多或少地和实际工作产生了断层。</p>
<p>流量控制和拥塞控制只是网络编程一小部分的内容，进程、线程、多路复用、异步 I/O 这些概念一摆出来，又会让人一头雾水。从哪里学？怎么学？</p>
<p>事实上，我认为学习高性能网络编程，掌握两个核心要点就可以了：<strong>第一就是理解网络协议，并在这个基础上和操作系统内核配合，感知各种网络 I/O 事件；第二就是学会使用线程处理并发</strong>。抓住这两个核心问题，也就抓住了高性能网络编程的“七寸”。我会从实践出发，单刀直入地展开，从问题的角度对这些看似枯燥的知识点进行阐述。</p>
<h2 id="2-第一模块：基础篇"><a href="#2-第一模块：基础篇" class="headerlink" title="2 第一模块：基础篇"></a>2 第一模块：基础篇</h2><h3 id="2-2-网络编程模型：认识客户端——服务器网络模型的基本概念"><a href="#2-2-网络编程模型：认识客户端——服务器网络模型的基本概念" class="headerlink" title="2.2  网络编程模型：认识客户端——服务器网络模型的基本概念"></a>2.2  <strong>网络编程模型：认识客户端——服务器网络模型的基本概念</strong></h3><h4 id="2-2-1-客户端——服务器网络编程模型"><a href="#2-2-1-客户端——服务器网络编程模型" class="headerlink" title="2.2.1 客户端——服务器网络编程模型"></a>2.2.1 <strong>客户端——服务器网络编程模型</strong></h4><p>这一讲我们主要介绍了客户端 - 服务器网络编程模型，初步介绍了 <code>IP</code> 地址、端口、子网掩</p>
<p>码和域名等基础概念，以下知识点你需要重点关注一下：</p>
<ol>
<li>网络编程需要牢牢树立起“客户端”和“服务器”模型，两者编程的方法和框架是明显</li>
</ol>
<p>不同的。</p>
<ol start="2">
<li>TCP 连接是客户端 - 服务器的 <code>IP</code> 和端口四元组唯一确定的，<code>IP</code> 是一台机器在网络世界</li>
</ol>
<p>的唯一标识。</p>
<ol start="3">
<li>有两种截然不同的传输层协议，面向连接的“数据流”协议 TCP，以及无连接的“数据</li>
</ol>
<p>报”协议 <code>UDP</code>。</p>
<p>从下一讲开始，我们将开始使用套接字编写我们的第一个客户端 - 服务器程序。</p>
<h3 id="2-3-套接字和地址：像电话和电话号码一样理解它们"><a href="#2-3-套接字和地址：像电话和电话号码一样理解它们" class="headerlink" title="2.3 套接字和地址：像电话和电话号码一样理解它们"></a>2.3 <strong>套接字和地址：像电话和电话号码一样理解它们</strong></h3><h4 id="2-3-1-socket-到底是什么？"><a href="#2-3-1-socket-到底是什么？" class="headerlink" title="2.3.1 socket 到底是什么？"></a>2.3.1 <strong>socket</strong> <strong>到底是什么？</strong></h4><p><img src="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/20.png" alt="20"></p>
<p>我们先从右侧的服务器端开始看，因为在客户端发起连接请求之前，服务器端必须初始化好。右侧的图显示的是服务器端初始化的过程，首先初始化 socket，之后服务器端需要执行 bind 函数，将自己的服务能力绑定在一个众所周知的地址和端口上，紧接着，服务器端执行 listen 操作，将原先的 socket 转化为服务端的 socket，服务端最后阻塞在 accept 上等待客户端请求的到来。</p>
<p>此时，服务器端已经准备就绪。客户端需要先初始化 socket，再执行 connect 向服务器端的地址和端口发起连接请求，这里的地址和端口必须是客户端预先知晓的。这个过程，就是著名的<strong>TCP 三次握手</strong>（Three-way Handshake）。下一篇文章，我会详细讲到 TCP 三次握手的原理。</p>
<p>一旦三次握手完成，客户端和服务器端建立连接，就进入了数据传输过程。</p>
<p>具体来说，客户端进程向操作系统内核发起 write 字节流写操作，内核协议栈将字节流通过网络设备传输到服务器端，服务器端从内核得到信息，将字节流从内核读入到进程中，并开始业务逻辑的处理，完成之后，服务器端再将得到的结果以同样的方式写给客户端。可以看到，<strong>一旦连接建立，数据的传输就不再是单向的，而是双向的，这也是 TCP 的一个显著特性</strong>。</p>
<p>当客户端完成和服务器端的交互后，比如执行一次 Telnet 操作，或者一次 HTTP 请求，需要和服务器端断开连接时，就会执行 close 函数，操作系统内核此时会通过原先的连接链路向服务器端发送一个 FIN 包，服务器收到之后执行被动关闭，这时候整个链路处于半关闭状态，此后，服务器端也会执行 close 函数，整个链路才会真正关闭。半关闭的状态下，发起 close 请求的一方在没有收到对方 FIN 包之前都认为连接是正常的；而在全关闭的状态下，双方都感知连接已经关闭。请你牢牢记住文章开头的那幅图，它是贯穿整个专栏的核心图之一。</p>
<p>讲这幅图的真正用意在于引入 socket 的概念，请注意，以上所有的操作，都是通过 socket 来完成的。无论是客户端的 connect，还是服务端的 accept，或者 read/write 操作等，<strong>socket 是我们用来建立连接，传输数据的唯一途径</strong>。</p>
<h3 id="2-4-TCP三次握手：怎么使用套接字格式建立连接？"><a href="#2-4-TCP三次握手：怎么使用套接字格式建立连接？" class="headerlink" title="2.4 TCP三次握手：怎么使用套接字格式建立连接？"></a>2.4 <strong>TCP三次握手：怎么使用套接字格式建立连接？</strong></h3><h4 id="（1）服务端准备连接的过程"><a href="#（1）服务端准备连接的过程" class="headerlink" title="（1）服务端准备连接的过程"></a><strong>（1）服务端准备连接的过程</strong></h4><h4 id="2-4-1-创建套接字"><a href="#2-4-1-创建套接字" class="headerlink" title="2.4.1 创建套接字"></a>2.4.1 <strong>创建套接字</strong></h4><p>要创建一个可用的套接字，需要使用下面的函数：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">socket</span><span class="params">(<span class="type">int</span> domain, <span class="type">int</span> type, <span class="type">int</span> protocol)</span></span></span><br></pre></td></tr></table></figure>

<p>type 可用的值是：</p>
<ol>
<li><strong><code>SOCK_STREAM</code>: 表示的是字节流，对应 <code>TCP</code>；</strong></li>
<li><strong><code>SOCK_DGRAM</code>： 表示的是数据报，对应 <code>UDP</code>；</strong></li>
<li><strong><code>SOCK_RAW</code>: 表示的是原始套接字。</strong></li>
</ol>
<h4 id="2-4-2-bind-设定电话号码"><a href="#2-4-2-bind-设定电话号码" class="headerlink" title="2.4.2 bind: 设定电话号码"></a>2.4.2 <strong>bind:</strong> <strong>设定电话号码</strong></h4><h4 id="2-4-3-listen：接上电话线，一切准备就绪"><a href="#2-4-3-listen：接上电话线，一切准备就绪" class="headerlink" title="2.4.3 listen：接上电话线，一切准备就绪"></a>2.4.3 <strong>listen：接上电话线，一切准备就绪</strong></h4><p>之后主动发起请求（通过调 用 connect 函数，后面会讲到）。通过 listen 函数，可以将原来的”主动”套接字转换为”被动”套接字，告诉操作系统内核：<strong>“我这个套接字是用来等待用户请求的。”当然，操作系统内核会为此做好接收用户请求的一切准备，比如完成连接队列。</strong></p>
<p>listen 函数的原型是这样的：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">listen</span> <span class="params">(<span class="type">int</span> socketfd, <span class="type">int</span> backlog)</span></span></span><br></pre></td></tr></table></figure>

<p>我来稍微解释一下。<strong>第一个参数 <code>socketfd</code> 为套接字描述符，第二个参数 <code>backlog</code>，官方的解释为未完成连接队列的大小，这个参数的大小决定了可以接收的并发数目。</strong>这个参数越大，并发数目理论上也会越大。但是参数过大也会占用过多的系统资源，一些系统，比如 <code>Linux</code> 并不允许对这个参数进行改变。对于 <code>backlog</code> 整个参数的设置有一些最佳实践，这里就不展开，后面结合具体的实例进行解读。</p>
<h4 id="2-4-4-accept-电话铃响起了……"><a href="#2-4-4-accept-电话铃响起了……" class="headerlink" title="2.4.4 accept: 电话铃响起了……"></a>2.4.4 <strong>accept:</strong> <strong>电话铃响起了……</strong></h4><p>accept 这个函数的作用就是连接建立之后，操作系统内核和应用程序之间的桥梁。它的原型是：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">accept</span><span class="params">(<span class="type">int</span> listensockfd, <span class="keyword">struct</span> sockaddr *cliaddr, <span class="type">socklen_t</span> *addrlen)</span></span></span><br></pre></td></tr></table></figure>

<p><strong>函数的第一个参数 <code>listensockfd</code> 是套接字，可以叫它为 <code>listen</code> 套接字，因为这就是前面通过 <code>bind</code>，<code>listen</code> 一系列操作而得到的套接字。</strong>函数的返回值有两个部分，第一个部分 <code>cliadd</code> 是通过指针方式获取的客户端的地址，<code>addrlen</code> 告诉我们地址的大小，这可以理解成当我们拿起电话机时，看到了来电显示，知道了对方的号码；另一个部分是函数的返回值，这个返回值是一个全新的描述字，代表了与客户端的连接。</p>
<p><em><strong><u>这里一定要注意有两个套接字描述字，第一个是监听套接字描述字 <code>listensockfd</code>，它是作为输入参数存在的；第二个是返回的已连接套接字描述字。</u></strong></em></p>
<p>你可能会问，为什么要把两个套接字分开呢？用一个不是挺好的么？</p>
<p>所以监听套接字一直都存在，它是要为成千上万的客户来服务的，直到这个监听套接字关闭；而一旦一个客户和服务器连接成功，完成了 TCP 三次握手，操作系统内核就为这个客户生成一个已连接套接字，让应用服务器使用这个<strong>已连接套接字</strong>和客户进行通信处理。如果应用服务器完成了对这个客户的服务，比如一次网购下单，一次付款成功，那么关闭的就是<strong>已连接套接字</strong>，这样就完成了 TCP 连接的释放。请注意，这个时候释放的只是这一个客户连接，其它被服务的客户连接可能还存在。最重要的是，监听套接字一直都处于“监听”状态，等待新的客户请求到达并服务。</p>
<h4 id="（2）客户端创建连接的过程"><a href="#（2）客户端创建连接的过程" class="headerlink" title="（2）客户端创建连接的过程"></a>（2）客户端创建连接的过程</h4><p>第一步还是和服务端一样，要<strong>建立一个套接字</strong>，方法和前面是一样的。</p>
<h4 id="2-4-5-connect-拨打电话"><a href="#2-4-5-connect-拨打电话" class="headerlink" title="2.4.5 connect: 拨打电话"></a>2.4.5 <strong>connect:</strong> <strong>拨打电话</strong></h4><p>客户端和服务器端的连接建立，是通过 connect 函数完成的。这是 connect 的构建函数：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">connect</span><span class="params">(<span class="type">int</span> sockfd, <span class="type">const</span> <span class="keyword">struct</span> sockaddr *servaddr, <span class="type">socklen_t</span> addrlen)</span></span></span><br></pre></td></tr></table></figure>

<p>函数的第一个参数 <code>sockfd</code> 是连接套接字，通过前面讲述的 <code>socket</code> 函数创建。第二个、第三个参数 <code>servaddr</code> 和 <code>addrlen</code> 分别代表指向套接字地址结构的指针和该结构的大小。套接字地址结构必须含有服务器的 <code>IP</code> 地址和端口号。</p>
<p>如果是 TCP 套接字，那么调用 connect 函数将激发 TCP 的三次握手过程，而且仅在连接</p>
<p>建立成功或出错时才返回。其中出错返回可能有以下几种情况：</p>
<ol>
<li><p>三次握手无法建立，客户端发出的 SYN 包没有任何响应，于是返回 TIMEOUT 错误。这种情况比较常见的原因是对应的服务端 <code>IP</code> 写错。</p>
</li>
<li><p>客户端收到了 <code>RST</code>（复位）回答，这时候客户端会立即返回 CONNECTION REFUSED 错误。这种情况比较常见于客户端发送连接请求时的请求端口写错，因为 <code>RST</code> 是 TCP 在发生错误时发送的一种 TCP 分节。产生 <code>RST</code> 的三个条件是：目的地为某端口的 SYN到达，然而该端口上没有正在监听的服务器（如前所述）；TCP 想取消一个已有连接；TCP 接收到一个根本不存在的连接上的分节。</p>
</li>
<li><p>客户发出的 SYN 包在网络上引起了”destination unreachable”，即目的不可达的错误。这种情况比较常见的原因是客户端和服务器端路由不通。</p>
</li>
</ol>
<h4 id="（3）著名的-TCP-三次握手：这一次不用背记"><a href="#（3）著名的-TCP-三次握手：这一次不用背记" class="headerlink" title="（3）著名的 TCP 三次握手：这一次不用背记"></a>（3）<strong>著名的</strong> <strong>TCP</strong> <strong>三次握手：这一次不用背记</strong></h4><p>下面是具体的过程：</p>
<ol>
<li><p>客户端的协议栈向服务器端发送了 SYN 包，并告诉服务器端当前发送序列号 j，客户端进入 SYNC_SENT 状态；</p>
</li>
<li><p>服务器端的协议栈收到这个包之后，和客户端进行 <code>ACK</code> 应答，应答的值为 j+1，表示对 SYN 包 j 的确认，同时服务器也发送一个 SYN 包，告诉客户端当前我的发送序列号为 k，服务器端进入 <code>SYNC_RCVD</code> 状态；</p>
</li>
<li><p>客户端协议栈收到 <code>ACK</code> 之后，使得应用程序从 connect 调用返回，表示客户端到服务器端的单向连接建立成功，客户端的状态为 ESTABLISHED，同时客户端协议栈也会对服务器端的 SYN 包进行应答，应答数据k+1；</p>
</li>
<li><p>应答包到达服务器端后，服务器端协议栈使得 accept 阻塞调用返回，这个时候服务器端到客户端的单向连接也建立成功，服务器端也进入 ESTABLISHED 状态。</p>
</li>
</ol>
<p><img src="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/21.png" alt="21"></p>
<h3 id="2-5-使用套接字进行读写：开始交流吧"><a href="#2-5-使用套接字进行读写：开始交流吧" class="headerlink" title="2.5 使用套接字进行读写：开始交流吧"></a>2.5 <strong>使用套接字进行读写：开始交流吧</strong></h3><h4 id="2-5-1-发送数据"><a href="#2-5-1-发送数据" class="headerlink" title="2.5.1 发送数据"></a>2.5.1 发送数据</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> <span class="function"><span class="type">ssize_t</span> <span class="title">write</span> <span class="params">(<span class="type">int</span> socketfd, <span class="type">const</span> <span class="type">void</span> *buffer, <span class="type">size_t</span> size)</span></span></span><br><span class="line"><span class="function">2 <span class="type">ssize_t</span> <span class="title">send</span> <span class="params">(<span class="type">int</span> socketfd, <span class="type">const</span> <span class="type">void</span> *buffer, <span class="type">size_t</span> size, <span class="type">int</span> flags)</span></span></span><br><span class="line"><span class="function">3 <span class="type">ssize_t</span> <span class="title">sendmsg</span><span class="params">(<span class="type">int</span> sockfd, <span class="type">const</span> <span class="keyword">struct</span> msghdr *msg, <span class="type">int</span> flags)</span></span></span><br></pre></td></tr></table></figure>

<p>第一个函数是常见的文件写函数，如果把 <code>socketfd</code> 换成文件描述符，就是普通的文件写入。</p>
<p>你看到这里可能会问，既然<strong>套接字描述符是一种特殊的描述符</strong>，那么在套接字描述符上调用 write 函数，应该和在普通文件描述符上调用 write 函数的行为是一致的，都是通过描述符句柄写入指定的数据。</p>
<h4 id="2-5-2-发送缓冲区"><a href="#2-5-2-发送缓冲区" class="headerlink" title="2.5.2 发送缓冲区"></a>2.5.2 <strong>发送缓冲区</strong></h4><p>你一定要建立一个概念，当 TCP 三次握手成功，TCP 连接成功建立后，操作系统内核会为每一个连接创建配套的基础设施，比如<strong>发送缓冲区</strong>。</p>
<p>发送缓冲区的大小可以通过套接字选项来改变，当我们的应用程序调用 write 函数时，实际所做的事情是把数据<strong>从应用程序中拷贝到操作系统内核的发送缓冲区中</strong>，并不一定是把数据通过套接字写出去。</p>
<p>这里有几种情况：</p>
<p>第一种情况很简单，<strong>操作系统内核的发送缓冲区足够大</strong>，可以直接容纳这份数据，那么皆大欢喜，我们的程序从 write 调用中退出，返回写入的字节数就是应用程序的数据大小。</p>
<p>第二种情况是，操作系统内核的发送缓冲区是够大了，不过还有数据没有发送完，或者数据发送完了，但是<strong>操作系统内核的发送缓冲区不足以容纳应用程序数据</strong>，在这种情况下，你预料的结果是什么呢？报错？还是直接返回？</p>
<p>操作系统内核并不会返回，也不会报错，而是<strong>应用程序被阻塞</strong>，也就是说应用程序在 write函数调用处停留，不直接返回。术语“挂起”也表达了相同的意思，不过“挂起”是从操作系统内核角度来说的。</p>
<p>别忘了，我们的操作系统内核是很聪明的，当 TCP 连接建立之后，它就开始运作起来。你可以把发送缓冲区想象成一条包裹流水线，有个聪明且忙碌的工人不断地从流水线上取出包裹（数据），这个工人会按照 <code>TCP/IP</code> 的语义，将取出的包裹（数据）封装成 TCP 的 <code>MSS</code> 包，以及 <code>IP</code> 的 <code>MTU</code> 包，最后走数据链路层将数据发送出去。这样我们的发送缓冲区就又空了一部分，于是又可以继续从应用程序搬一部分数据到发送缓冲区里，这样一直进行下去，到某一个时刻，应用程序的数据可以完全放置到发送缓冲区里。在这个时候，write 阻塞调用返回。注意返回的时刻，应用程序数据并没有全部被发送出去，发送缓冲区里还有部分数据，这部分数据会在稍后由操作系统内核通过网络发送出去。</p>
<h4 id="2-5-3-小结"><a href="#2-5-3-小结" class="headerlink" title="2.5.3 小结"></a>2.5.3 小结</h4><p>这一讲重点讲述了通过 send 和 read 来收发数据包，你需要牢记以下两点：</p>
<ol>
<li>对于 send 来说，返回成功仅仅表示数据写到发送缓冲区成功，并不表示对端已经成功收到。</li>
<li>对于 read 来说，需要循环读取数据，并且需要考虑 <code>EOF</code> 等异常条件。</li>
</ol>
<h3 id="2-6-嗨，别忘了UDP这个小兄弟"><a href="#2-6-嗨，别忘了UDP这个小兄弟" class="headerlink" title="2.6 嗨，别忘了UDP这个小兄弟"></a>2.6 <strong>嗨，别忘了<code>UDP</code>这个小兄弟</strong></h3><p>同样的，我们也可以给 <code>UDP</code> 找一个类似的例子，这个例子就是邮寄明信片。在这个例子中，发信方在明信片中填上了接收方的地址和邮编，投递到邮局的邮筒之后，就可以不管了。发信方也可以给这个接收方再邮寄第二张、第三张，甚至是第四张明信片，但是这几张明信片之间是没有任何关系的，他们的到达顺序也是不保证的，有可能最后寄出的第四张明信片最先到达接收者的手中，因为没有序号，接收者也不知道这是第四张寄出的明信片；而且，即使接收方没有收到明信片，也没有办法重新邮寄一遍该明信片。</p>
<p><strong><code>UDP</code> 不保证报文的有效传递，不保证报文的有序，也就是说使用 <code>UDP</code> 的时候，我们需要 做好丢包、重传、报文组装等工作。</strong></p>
<h4 id="2-6-1-UDP-编程"><a href="#2-6-1-UDP-编程" class="headerlink" title="2.6.1 UDP 编程"></a>2.6.1 <strong><code>UDP</code></strong> <strong>编程</strong></h4><p><img src="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/28.png" alt="28"></p>
<p>我们看到服务器端创建 <code>UDP</code> 套接字之后，绑定到本地端口，调用 <code>recvfrom</code> 函数等待客户端的报文发送；客户端创建套接字之后，调用 <code>sendto</code> 函数往目标地址和端口发送 <code>UDP</code> 报文，然后客户端和服务器端进入互相应答过程。</p>
<p><code>recvfrom</code> 和 <code>sendto</code> 是 <code>UDP</code> 用来接收和发送报文的两个主要函数：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">ssize_t</span> <span class="title">recvfrom</span><span class="params">(<span class="type">int</span> sockfd, <span class="type">void</span> *buff, <span class="type">size_t</span> nbytes, <span class="type">int</span> flags, <span class="keyword">struct</span> sockaddr *from, <span class="type">socklen_t</span> *addrlen)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">ssize_t</span> <span class="title">sendto</span><span class="params">(<span class="type">int</span> sockfd, <span class="type">const</span> <span class="type">void</span> *buff, <span class="type">size_t</span> nbytes, <span class="type">int</span> flags, <span class="type">const</span> <span class="keyword">struct</span> sockaddr *to, <span class="type">socklen_t</span> *addrlen)</span></span>;</span><br></pre></td></tr></table></figure>

<p>我们先来看一下 <code>recvfrom</code> 函数。</p>
<p><code>sockfd</code>、<code>buff</code> 和 <code>nbytes</code> 是前三个参数。<code>sockfd</code> 是本地创建的套接字描述符，<code>buff</code> 指向本地的缓存，<code>nbytes</code> 表示最大接收数据字节。第四个参数 flags 是和 I/O 相关的参数，这里我们还用不到，设置为 0。</p>
<p>后面两个参数 <code>from</code> 和 <code>addrlen</code>，实际上是返回对端发送方的地址和端口等信息，这和 <code>TCP</code> 非常不一样，**<code>TCP</code> 是通过 <code>accept</code> 函数拿到的描述字信息来决定对端的信息。另外<code>UDP</code> 报文每次接收都会获取对端的信息，也就是说报文和报文之间是没有上下文的。**函数的返回值告诉我们实际接收的字节数。</p>
<p>接下来看一下 <code>sendto</code> 函数。</p>
<p><code>sendto</code> 函数中的前三个参数为 <code>sockfd</code>、<code>buff</code> 和 <code>nbytes</code>。<code>sockfd</code> 是本地创建的套接字描述符，<code>buff</code> 指向发送的缓存，<code>nbytes</code> 表示发送字节数。第四个参数 <code>flags</code> 依旧设置为 0。后面两个参数 <code>to</code> 和 <code>addrlen</code>，表示发送的对端地址和端口等信息。</p>
<p>函数的返回值告诉我们实际接收的字节数。</p>
<h3 id="2-7-What-还有本地套接字？"><a href="#2-7-What-还有本地套接字？" class="headerlink" title="2.7 What?还有本地套接字？"></a>2.7 <strong>What?还有本地套接字？</strong></h3><p>本地套接字是 <code>IPC</code>，也就是本地进程间通信的一种实现方式。除了本地套接字以外，其它技术，诸如管道、共享消息队列等也是进程间通信的常用方法，但因为本地套接字 开发便捷，接受度高，所以普遍适用于在同一台主机上进程间通信的各种场景。</p>
<h4 id="2-7-1-从例子开始"><a href="#2-7-1-从例子开始" class="headerlink" title="2.7.1 从例子开始"></a>2.7.1 <strong>从例子开始</strong></h4><p>现在最火的云计算技术是什么？无疑是 <code>Kubernetes</code> 和 <code>Docker</code>。在 <code>Kubernetes</code> 和 <code>Docker</code> 的技术体系中，有很多优秀的设计，比如 <code>Kubernetes</code> 的 <code>CRI</code>（Container Runtime Interface），其思想是将 <code>Kubernetes</code> 的主要逻辑和 Container Runtime 的实现解耦。</p>
<p>我们可以通过 <code>netstat</code> 命令查看 Linux 系统内的本地套接字状况，下面这张图列出了路径为 <code>/var/run/dockershim.socket</code> 的 stream 类型的本地套接字，可以清楚地看到开启这个套接字的进程为 <code>kubelet</code>。<code>kubelet</code> 是 <code>Kubernetes</code> 的一个组件，这个组件负责将控制器和调度器的命令转化为单机上的容器实例。为了实现和容器运行时的解耦，<code>kubelet</code> 设计了基于本地套接字的客户端 - 服务器 <code>GRPC</code> 调用。</p>
<p><em><strong><u>这部分详见<code>PPT</code></u></strong></em></p>
<p>书籍推荐：</p>
<h3 id="2-8-工欲善其事必先利其器：学会使用各种工具"><a href="#2-8-工欲善其事必先利其器：学会使用各种工具" class="headerlink" title="2.8 工欲善其事必先利其器：学会使用各种工具"></a>2.8 <strong>工欲善其事必先利其器：学会使用各种工具</strong></h3><p>上一讲我们讲到了本地套接字，加上前面介绍的 <code>TCP</code>、<code>UDP</code> 套接字，你会发现我们已经比较全面地接触了套接字。</p>
<p>其实在平常使用套接字开发和测试过程中，我们总会碰到这样或那样的问题。学会对这些问题进行诊断和分析，其实需要不断地积累经验。而 Linux 平台下提供的各种网络工具，则为我们进行诊断分析提供了很好的帮助。在这一讲里，我将会选择几个重点的工具逐一介绍。</p>
<h4 id="2-8-1-必备工具-ping"><a href="#2-8-1-必备工具-ping" class="headerlink" title="2.8.1 必备工具: ping"></a>2.8.1 <strong>必备工具: ping</strong></h4><p>我使用 ping 命令探测了和新浪网的网络连通性。可以看到，每次显示是按照 sequence 序列号排序显示的，一并显示的，也包括 TTL（time to live），反映了两个 <code>IP</code> 地址之间传输的时间。最后还显示了 ping 命令的统计信息，如最小时间、平均时间等。</p>
<p>我们需要经常和 Linux 下的 ping 命令打交道，那么 ping 命令的原理到底是什么呢？它是基于 <code>TCP</code> 还是 <code>UDP</code> 开发的？都不是。其实，ping 是基于一种叫做 <code>ICMP</code> 的协议开发的，<code>ICMP</code> 又是一种基于 <code>IP</code> 协议的控制协议，翻译为网际控制协议。</p>
<h4 id="2-8-2-基本命令-ifconfig"><a href="#2-8-2-基本命令-ifconfig" class="headerlink" title="2.8.2 基本命令: ifconfig"></a>2.8.2 <strong>基本命令: <code>ifconfig</code></strong></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">1 vagrant@ubuntu-xenial-01:~$ ifconfig</span><br><span class="line">2 cni0 Link encap:Ethernet HWaddr 0a:58:0a:f4:00:01</span><br><span class="line">3 inet addr:10.244.0.1 Bcast:0.0.0.0 Mask:255.255.255.0</span><br><span class="line">4 inet6 addr: fe80::401:b4ff:fe51:bcf9/64 Scope:Link</span><br><span class="line">5 UP BROADCAST RUNNING MULTICAST MTU:1450 Metric:1</span><br><span class="line">6 RX packets:2133 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">7 TX packets:2216 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">8 collisions:0 txqueuelen:1000</span><br><span class="line">9 RX bytes:139381 (139.3 KB) TX bytes:853302 (853.3 KB)</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12 docker0 Link encap:Ethernet HWaddr 02:42:93:0f:f7:11</span><br><span class="line">13 inet addr:172.17.0.1 Bcast:0.0.0.0 Mask:255.255.0.0</span><br><span class="line">14 inet6 addr: fe80::42:93ff:fe0f:f711/64 Scope:Link</span><br><span class="line">15 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1</span><br><span class="line">16 RX packets:653 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">17 TX packets:685 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">18 collisions:0 txqueuelen:0</span><br><span class="line">19 RX bytes:49542 (49.5 KB) TX bytes:430826 (430.8 KB)</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22 enp0s3 Link encap:Ethernet HWaddr 02:54:ad:ea:60:2e</span><br><span class="line">23 inet addr:10.0.2.15 Bcast:10.0.2.255 Mask:255.255.255.0</span><br><span class="line">24 inet6 addr: fe80::54:adff:feea:602e/64 Scope:Link</span><br><span class="line">25 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1</span><br><span class="line">26 RX packets:7951 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">27 TX packets:4123 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">28 collisions:0 txqueuelen:1000</span><br><span class="line">29 RX bytes:5081047 (5.0 MB) TX bytes:385600 (385.6 KB)</span><br></pre></td></tr></table></figure>

<p>我稍微解释一下这里面显示的数据。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Link encap:Ethernet HWaddr 02:54:ad:ea:60:2e</span><br></pre></td></tr></table></figure>

<p>上面这段表明这是一个以太网设备，MAC 地址为 <code>02:54:ad:ea:60:2e</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1 inet addr:10.0.2.15 Bcast:10.0.2.255 Mask:255.255.255.0</span><br><span class="line">2 inet6 addr: fe80::54:adff:feea:602e/64 Scope:Link</span><br></pre></td></tr></table></figure>

<p>这里显示的是网卡的 <code>IPv4</code> 和 <code>IPv6</code> 地址，其中 <code>IPv4</code> 还显示了该网络的子网掩码以及广播地址。</p>
<p>在每个 <code>IPv4</code> 子网中，有一个特殊地址被保留作为子网广播地址，比如这里的 <code>10.0.2.255</code>就是这个子网的广播地址。当向这个地址发送请求时，就会向以太网网络上的一组主机发送请求。</p>
<p>通常来说，这种被称作广播（broadcast）的技术，是用 <code>UDP</code> 来实现的。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1</span><br></pre></td></tr></table></figure>

<p>这里显示的是网卡的状态，<code>MTU</code> 是最大传输单元的意思，表示的是链路层包的大小。1500表示的是字节大小。</p>
<p>Metric 大家可能不知道是干啥用的，这里解释下，<strong>Linux 在一台主机上可以有多个网卡设备，很可能有这么一种情况，多个网卡可以路由到目的地。一个简单的例子是在同时有无线网卡和有线网卡的情况下，网络连接是从哪一个网卡设备上出去的？Metric 就是用来确定多块网卡的优先级的，数值越小，优先级越高，1 为最高级。</strong></p>
<h4 id="2-8-3-netstat-和-lsof：对网络状况了如指掌"><a href="#2-8-3-netstat-和-lsof：对网络状况了如指掌" class="headerlink" title="2.8.3 netstat 和 lsof：对网络状况了如指掌"></a>2.8.3 <strong><code>netstat</code></strong> <strong>和</strong> <strong><code>lsof</code>：对网络状况了如指掌</strong></h4><p>在平时的工作中，我们最常碰到的问题就是某某进程对应的网络状况如何？是不是连接被打爆了？还是有大量的 TIME_WAIT 连接？</p>
<p><code>netstat</code> 可以帮助我们了解当前的网络连接状况，比如我想知道当前所有的连接详情，就可以使用下面这行命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat -alepn</span><br></pre></td></tr></table></figure>

<p>可能的结果为：</p>
<p><img src="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/22.png" alt="22"></p>
<p><code>netstat</code> 会把所有 <code>IPv4</code> 形态的 TCP，<code>IPV6</code> 形态的 <code>TCP</code>、<code>UDP</code> 以及 <code>UNIX</code> 域的套接字都显示出来。</p>
<p>对于 TCP 类型来说，最大的好处是可以清楚地看到一条 TCP 连接的四元组（源地址、源端口、目的地地址和目的端口）。</p>
<p>例如这里的一条信息：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">tcp        0      0 127.0.0.1:2379          127.0.0.1:52464         ESTABLISHED 0          27710       3496/etcd</span><br></pre></td></tr></table></figure>

<p>它表达的意思是本地 127.0.0.1 的端口 52464 连上本地 127.0.0.1 的端口 2379，状态为ESTABLISHED，本地进程为 <code>etcd</code>，进程为 3496。</p>
<p><strong>这在实战分析的时候非常有用，比如你可以很方便地知道，在某个时候是不是有很多 TIME_WAIT 的 TCP 连接，导致端口号被占用光，以致新的连接分配不了。</strong></p>
<p>当然，我们也可以只对 UNIX 套接字进行筛查。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat Socket -x -alepn</span><br></pre></td></tr></table></figure>

<p><img src="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/23.png" alt="23"></p>
<p>UNIX 套接字的结果稍有不同，最关键的信息是 Path，这个信息显示了本地套接字监听的文件路径，比如这条：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">unix  3      [ ]         STREAM     CONNECTED     23209    1400/dockerd        /var/run/docker.sock</span><br></pre></td></tr></table></figure>

<p>这其实就是大名鼎鼎的 Docker 在本地套接字的监听路径。<code>/var/run/docker.sock</code> 是本地套接字监听地址，<code>dockerd</code> 是进程名称，1400 是进程号。</p>
<p>netstat 命令可以选择的参数非常之多，这里只关注了几个简单的场景，你可以通过帮助命</p>
<p>令或者查阅文档获得更多的信息。</p>
<p><strong><code>lsof</code> 的常见用途之一是帮助我们找出在指定的 <code>IP</code> 地址或者端口上打开套接字的进程，而<code>netstat</code> 则告诉我们 <code>IP</code> 地址和端口使用的情况，以及各个 <code>TCP</code> 连接的状态。<code>Isof</code> 和<code>netstst</code> 可以结合起来一起使用。</strong></p>
<p>比如说，我们可以通过 <code>lsof</code> 查看到底是谁打开了这个文件：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lsof /var/run/docker.sock</span><br></pre></td></tr></table></figure>

<p>下面这张图显示了是 <code>dockerd</code> 打开了这个本地文件套接字：</p>
<p><img src="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/24.png" alt="24"></p>
<p><code>lsof</code> 还有一个非常常见的用途。<strong>如果我们启动了一个服务器程序，发现这个服务器需要绑 定的端口地址已经被占用，内核报出“该地址已在使用”的出错信息，我们可以使用 <code>lsof</code> 找出正在使用该端口的那个进程。比如下面这个代码，就帮我们找到了使用 8080 端口的那 个进程，从而帮助我们定位问题。</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lsof -i :8080</span><br></pre></td></tr></table></figure>

<h4 id="2-8-4-抓包利器-tcpdump"><a href="#2-8-4-抓包利器-tcpdump" class="headerlink" title="2.8.4 抓包利器: tcpdump"></a>2.8.4 <strong>抓包利器: <code>tcpdump</code></strong></h4><p><code>tcpdump</code> 具有非常强大的过滤和匹配功能。</p>
<p>比如说指定网卡：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump -i eth0</span><br></pre></td></tr></table></figure>

<p>再比如说指定来源：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump src host hostname</span><br></pre></td></tr></table></figure>

<p>我们再来一个复杂一点的例子。这里抓的包是 TCP，且端口是 80，包来自 <code>IP</code> 地址为 192.168.1.25 的主机地址。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump &#x27;tcp and port 80 and src host 192.168.1.25&#x27;</span><br></pre></td></tr></table></figure>

<p>如果我们对 TCP 协议非常熟悉，还可以写出这样的 <code>tcpdump</code> 命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump &#x27;tcp and port 80 and tcp[13:1]&amp;2 != 0&#x27;</span><br></pre></td></tr></table></figure>

<p>这里 <code>tcp[13:1]</code> 表示的是 TCP 头部开始处偏移为 13 的字节，如果这个值为 2，说明设置了 <code>SYN</code> 分节，当然，我们也可以设置成其他值来获取希望类型的分节。</p>
<p><code>tcpdump</code> 在开启抓包的时候，会自动创建一个类型为 <code>AF_PACKET</code> 的网络套接口，并向系统内核注册。当网卡接收到一个网络报文之后，它会遍历系统中所有已经被注册的网络协议，包括其中已经注册了的 AF_PACKET 网络协议。系统内核接下来就会将网卡收到的报文发送给该协议的回调函数进行一次处理，回调函数可以把接收到的报文完完整整地复制一份，假装是自己接收到的报文，然后交给 <code>tcpdump</code> 程序，进行各种条件的过滤和判断，再对报文进行解析输出。</p>
<p>下面这张图显示的是 <code>tcpdump</code> 的输出格式：</p>
<p><img src="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/25.png" alt="25"></p>
<p>首先我们看到的是时间戳，之后类似 192.168.33.11.41388 &gt; 192.168.33.11.6443 这样的，显示的是源地址（192.168.33.11.41388）到目的地址（192.168.33.11.6443）；<strong>然后Flags [ ] 是包的标志，[P] 表示是数据推送，比较常见的包格式如下</strong>：</p>
<ol>
<li><strong>[S]：SYN，表示开始连接</strong></li>
<li><strong>[.]：没有标记，一般是确认</strong></li>
<li><strong>[P]：PSH，表示数据推送</strong></li>
<li><strong>[F]：FIN，表示结束连接</strong></li>
<li><strong>[R] ：RST，表示重启连接</strong></li>
</ol>
<p>我们可以看到最后有几个数据，它们代表的含义如下：</p>
<p><em><strong>seq：包序号，就是 TCP 的确认分组</strong></em></p>
<p><em><strong>cksum：校验码</strong></em></p>
<p><em><strong>win：滑动窗口大小</strong></em></p>
<p><em><strong>length：承载的数据（payload）长度 length，如果没有数据则为 0</strong></em></p>
<p>此外，tcpdump 还可以对每条 TCP 报文的细节进行显示，让我们可以看到每条报文的详细字节信息。这在对报文进行排查的时候很有用。</p>
<h4 id="2-8-5-小结"><a href="#2-8-5-小结" class="headerlink" title="2.8.5 小结"></a>2.8.5 <strong>小结</strong></h4><p>我再来总结一下这几个命令的作用：</p>
<ol>
<li><strong>ping 可以用来帮助我们进行网络连通性的探测。</strong></li>
<li><strong>ifconfig，用来显示当前系统中的所有网络设备。</strong></li>
<li><strong>netstat 和 lsof 可以查看活动的连接状况。</strong></li>
<li><strong>tcpdump 可以对各种奇怪的环境进行抓包，进而帮我们了解报文，排查问题。</strong></li>
</ol>
<h2 id="3-第二模块：提高篇"><a href="#3-第二模块：提高篇" class="headerlink" title="3 第二模块：提高篇"></a>3 第二模块：提高篇</h2><h3 id="3-1-TIME-WAIT：隐藏在细节下的魔鬼"><a href="#3-1-TIME-WAIT：隐藏在细节下的魔鬼" class="headerlink" title="3.1 TIME_WAIT：隐藏在细节下的魔鬼"></a>3.1 <strong>TIME_WAIT：隐藏在细节下的魔鬼</strong></h3><p>在四次挥手的过程中，<strong>发起连接断开的一方会有一段时间处于 TIME_WAIT 的状态</strong>，你知道 TIME_WAIT 是用来做什么的么？在面试和实战中，TIME_WAIT 相关的问题始终是绕不过去的一道难题。</p>
<h4 id="3-1-1-TIME-WAIT发生的场景"><a href="#3-1-1-TIME-WAIT发生的场景" class="headerlink" title="3.1.1 TIME_WAIT发生的场景"></a>3.1.1 <strong>TIME_WAIT发生的场景</strong></h4><p>让我们先从一例线上故障说起。在一次升级线上应用服务之后，我们发现该服务的可用性变得时好时坏，一段时间可以对外提供服务，一段时间突然又不可以，大家都百思不得其解。运维同学登录到服务所在的主机上，<strong>使用 <code>netstat</code> 命令查看后才发现，主机上有成千上万处于 TIME_WAIT 状态的连接。</strong></p>
<p>经过层层剖析后，我们发现罪魁祸首就是 TIME_WAIT。为什么呢？我们这个应用服务需要通过发起 TCP 连接对外提供服务。每个连接会占用一个本地端口，当在高并发的情况下，TIME_WAIT 状态的连接过多，多到把本机可用的端口耗尽，应用服务对外表现的症状，就是不能正常工作了。<strong>当过了一段时间之后，处于 TIME_WAIT 的连接被系统回收并关闭后，释放出本地端口可供使用，应用服务对外表现为，可以正常工作。这样周而复始，便会出现了一会儿不可以，过一两分钟又可以正常工作的现象。</strong></p>
<p>那么为什么会产生这么多的 TIME_WAIT 连接呢？</p>
<p><img src="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/26.png" alt="26"></p>
<p>TCP 连接终止时，主机 1 先发送 FIN 报文，主机 2 进入 CLOSE_WAIT 状态，并发送一个 <code>ACK</code> 应答，同时，主机 2 通过 read 调用获得 <code>EOF</code>，并将此结果通知应用程序进行主动关闭操作，发送 FIN 报文。主机 1 在接收到 FIN 报文后发送 <code>ACK</code> 应答，此时主机 1 进入 TIME_WAIT 状态。</p>
<p><strong>主机 1 在 TIME_WAIT 停留持续时间是固定的，是最长分节生命期 <code>MSL</code>（maximum segment lifetime）的两倍，一般称之为 <code>2MSL</code>。</strong>和大多数 BSD 派生的系统一样，Linux 系统里有一个硬编码的字段，名称<code>TCP_TIMEWAIT_LEN</code>，其值为 60 秒。也就是说，<strong>Linux 系统停留在 TIME_WAIT 的时间为固定的 60 秒。</strong>过了这个时间之后，主机 1 就进入 CLOSED 状态。为什么是这个时间呢？你可以先想一想，稍后我会给出解答。</p>
<p>你一定要记住一点，<strong>只有发起连接终止的一方会进入 TIME_WAIT 状态</strong>。这一点面试的时候经常会被问到。</p>
<h4 id="3-1-2-TIME-WAIT-的作用"><a href="#3-1-2-TIME-WAIT-的作用" class="headerlink" title="3.1.2 TIME_WAIT 的作用"></a>3.1.2 <strong>TIME_WAIT 的作用</strong></h4><p>你可能会问，为什么不直接进入 CLOSED 状态，而要停留在 TIME_WAIT 这个状态？</p>
<p>这要从两个方面来说。</p>
<p>首先，这样做是<strong>为了确保最后的 <code>ACK</code> 能让被动关闭方接收，从而帮助其正常关闭。</strong>TCP 在设计的时候，做了充分的容错性设计，比如，TCP 假设报文会出错，需要重传。在这里，如果图中主机 1 的 <code>ACK</code> 报文没有传输成功，那么主机 2 就会重新发送 FIN 报文。</p>
<p><strong>如果主机 1 没有维护 TIME_WAIT 状态，而直接进入 CLOSED 状态，它就失去了当前状态的上下文，只能回复一个 <code>RST</code> 操作，从而导致被动关闭方出现错误。现在主机 1 知道自己处于 TIME_WAIT 的状态，就可以在接收到 FIN 报文之后，重新发出一个 <code>ACK</code> 报文，使得主机 2 可以进入正常的 CLOSED 状态。</strong></p>
<p><strong>第二个理由和连接“化身”和报文迷走有关系，为了让旧连接的重复分节在网络中自然消失。</strong></p>
<p>我们知道，在网络中，经常会发生报文经过一段时间才能到达目的地的情况，产生的原因是多种多样的，如路由器重启，链路突然出现故障等。如果迷走报文到达时，发现 TCP 连接四元组（源 IP，源端口，目的 IP，目的端口）所代表的连接不复存在，那么很简单，这个报文自然丢弃。</p>
<p>我们考虑这样一个场景，在原连接中断后，又重新创建了一个原连接的“化身”，说是化身其实是因为这个连接和原先的连接四元组完全相同，<strong>如果迷失报文经过一段时间也到达，那么这个报文会被误认为是连接“化身”的一个 TCP 分节，这样就会对 TCP 通信产生影响。</strong></p>
<p>划重点，<code>2MSL</code> 的时间是<strong>从主机 1 接收到 FIN 后发送 <code>ACK</code> 开始计时的</strong>；<strong>如果在 TIME_WAIT 时间内，因为主机 1 的 <code>ACK</code> 没有传输到主机 2，主机 1 又接收到了主机 2 重发的 FIN 报文，那么 <code>2MSL</code> 时间将重新计时。</strong>道理很简单，因为 <code>2MSL</code> 的时间，目的是为了让旧连接的所有报文都能自然消亡，现在主机 1 重新发送了 <code>ACK</code> 报文，自然需要重新计时，以便防止这个 <code>ACK</code> 报文对新可能的连接化身造成干扰。</p>
<h4 id="3-1-3-TIME-WAIT的危害"><a href="#3-1-3-TIME-WAIT的危害" class="headerlink" title="3.1.3 TIME_WAIT的危害"></a>3.1.3 <strong>TIME_WAIT的危害</strong></h4><p>过多的 TIME_WAIT 的主要危害有两种。</p>
<p><strong>第一是内存资源占用，这个目前看来不是太严重，基本可以忽略。</strong></p>
<p><strong>第二是对端口资源的占用，一个 TCP 连接至少消耗一个本地端口。</strong>要知道，端口资源也是有限的，一般可以开启的端口为 32768～61000 ，也可以通过<code>net.ipv4.ip_local_port_range</code>指定，如果 TIME_WAIT 状态过多，会导致无法创建新连接。这个也是我们在一开始讲到的那个例子。</p>
<h4 id="3-1-4-如何优化TIME-WAIT"><a href="#3-1-4-如何优化TIME-WAIT" class="headerlink" title="3.1.4 如何优化TIME_WAIT"></a>3.1.4 <strong>如何优化TIME_WAIT</strong></h4><p>在高并发的情况下，如果我们想对 TIME_WAIT 做一些优化，来解决我们一开始提到的例子，该如何办呢？</p>
<p><strong><code>net.ipv4.tcp_max_tw_buckets</code></strong></p>
<p>一个暴力的方法是通过 sysctl 命令，将系统值调小。这个值默认为 18000，当系统中处于 TIME_WAIT 的连接一旦超过这个值时，系统就会将所有的 TIME_WAIT 连接状态重置，并且只打印出警告信息。这个方法过于暴力，而且治标不治本，带来的问题远比解决的问题多，不推荐使用。</p>
<p><strong>SO_LINGER</strong> <strong>的设置</strong></p>
<p>第二种可能为跨越 TIME_WAIT 状态提供了一个可能，不过是一个非常危险的行为，<strong>不值得提倡</strong>。</p>
<p><strong>net.ipv4.tcp_tw_reuse：更安全的设置</strong></p>
<p>这段话的大意是从协议角度理解如果是安全可控的，可以复用处于 TIME_WAIT 的套接字为新的连接所用。</p>
<p><strong>那么什么是协议角度理解的安全可控呢？主要有两点：</strong></p>
<ol>
<li><strong>只适用于连接发起方（C/S 模型中的客户端）；</strong></li>
<li><strong>对应的 TIME_WAIT 状态的连接创建时间超过 1 秒才可以被复用。</strong></li>
</ol>
<p>使用这个选项，还有一个前提，需要打开对 TCP 时间戳的支持，即<code>net.ipv4.tcp_timestamps=1</code>（默认即为 1）。</p>
<p><strong>要知道，TCP 协议也在与时俱进，RFC 1323 中实现了 TCP 拓展规范，以便保证 TCP 的高可用，并引入了新的 TCP 选项，两个 4 字节的时间戳字段，用于记录 TCP 发送方的当前时间戳和从对端接收到的最新时间戳。由于引入了时间戳，我们在前面提到的 2MSL 问题就不复存在了，因为重复的数据包会因为时间戳过期被自然丢弃。</strong></p>
<p>思考题：</p>
<ol>
<li><p>最大分组 MSL 是 TCP 分组在网络中存活的最长时间，你知道这个最长时间是如何达成的？换句话说，是怎么样的机制，可以保证在 MSL 达到之后，报文就自然消亡了呢？</p>
</li>
<li><p>RFC 1323 引入了 TCP 时间戳，那么这需要在发送方和接收方之间定义一个统一的时钟吗？</p>
</li>
</ol>
<h3 id="3-2-优雅地关闭还是粗暴地关闭"><a href="#3-2-优雅地关闭还是粗暴地关闭" class="headerlink" title="3.2 优雅地关闭还是粗暴地关闭 ?"></a>3.2 <strong>优雅地关闭还是粗暴地关闭</strong> <strong>?</strong></h3><p>我们知道，一个 TCP 连接需要经过三次握手进入数据传输阶段，最后来到连接关闭阶段。在最后的连接关闭阶段，我们需要重点关注的是“半连接”状态。</p>
<p>举个例子，客户端主动发起连接的中断，将自己到服务器端的数据流方向关闭，此时，客户端不再往服务器端写入数据，服务器端读完客户端数据后就不会再有新的报文到达。但这并不意味着，TCP 连接已经完全关闭，很有可能的是，<strong>服务器端正在对客户端的最后报文进行处理，比如去访问数据库，存入一些数据；或者是计算出某个客户端需要的值，当完成这些操作之后，服务器端把结果通过套接字写给客户端，我们说这个套接字的状态此时是“半关闭”的。</strong>最后，服务器端才有条不紊地关闭剩下的半个连接，结束这一段 TCP 连接的使命。</p>
<p>当然，我这里描述的，是服务器端“优雅”地关闭了连接。如果服务器端处理不好，就会导致最后的关闭过程是“粗暴”的，达不到我们上面描述的“优雅”关闭的目标，形成的后果，很可能是服务器端处理完的信息没办法正常传送给客户端，破坏了用户侧的使用场景。</p>
<p>接下来我们就来看看关闭连接时，都有哪些方式呢？</p>
<h4 id="3-2-1-close-函数"><a href="#3-2-1-close-函数" class="headerlink" title="3.2.1 close 函数"></a>3.2.1 close 函数</h4><p>首先，我们来看最常见的 close 函数：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">close</span><span class="params">(<span class="type">int</span> sockfd)</span></span></span><br></pre></td></tr></table></figure>

<p>这个函数很简单，对已连接的套接字执行 close 操作就可以，若成功则为 0，若出错则为-1。</p>
<p>这个函数会对套接字引用计数减一，一旦发现套接字引用计数到 0，就会对套接字进行彻底释放，并且会关闭<strong>TCP 两个方向的数据流</strong>。</p>
<p>套接字引用计数是什么意思呢？<strong>因为套接字可以被多个进程共享，你可以理解为我们给每个套接字都设置了一个积分，如果我们通过 fork 的方式产生子进程，套接字就会积分 +1，如果我们调用一次 close 函数，套接字积分就会 -1。这就是套接字引用计数的含义。</strong></p>
<p>close 函数具体是如何关闭两个方向的数据流呢？</p>
<p>在<strong>输入方向</strong>，系统内核会将该套接字设置为不可读，任何读操作都会返回异常。</p>
<p>在<strong>输出方向</strong>，系统内核尝试将发送缓冲区的数据发送给对端，并最后向对端发送一个 FIN</p>
<p>报文，接下来如果再对该套接字进行写操作会返回异常。</p>
<p>如果对端没有检测到套接字已关闭，还继续发送报文，就会收到一个 RST 报文，告诉对端：“Hi, 我已经关闭了，别再给我发数据了。”</p>
<p>我们会发现，<strong>close 函数并不能帮助我们关闭连接的一个方向</strong>，那么如何在需要的时候关闭一个方向呢？幸运的是，设计 TCP 协议的人帮我们想好了解决方案，这就是 shutdown 函数。</p>
<h4 id="3-2-2-shutdown函数"><a href="#3-2-2-shutdown函数" class="headerlink" title="3.2.2 shutdown函数"></a>3.2.2 <strong>shutdown函数</strong></h4><p>shutdown 函数的原型是这样的：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">shutdown</span><span class="params">(<span class="type">int</span> sockfd, <span class="type">int</span> howto)</span></span></span><br></pre></td></tr></table></figure>

<p>对已连接的套接字执行 shutdown 操作，若成功则为 0，若出错则为 -1。</p>
<p>howto 是这个函数的设置选项，它的设置有<strong>三个主要选项</strong>：</p>
<ol>
<li>SHUT_RD(0)：关闭连接的“读”这个方向，对该套接字进行读操作直接返回 EOF<strong>。从数据角度来看，套接字上接收缓冲区已有的数据将被丢弃，如果再有新的数据流到达，会对数据进行 ACK，然后悄悄地丢弃。也就是说，对端还是会接收到 ACK，在这种情况下根本不知道数据已经被丢弃了。</strong></li>
<li>SHUT_WR(1)：关闭连接的“写”这个方向，这就是常被称为”半关闭“的连接。此时，<strong>不管套接字引用计数的值是多少，都会直接关闭连接的写方向。套接字上发送缓冲区已有的数据将被立即发送出去，并发送一个 FIN 报文给对端。应用程序如果对该套接字进行写操作会报错。</strong></li>
<li>SHUT_RDWR(2)：相当于 SHUT_RD 和 SHUT_WR 操作各一次，关闭套接字的读和写两个方向。</li>
</ol>
<p>讲到这里，不知道你是不是有和我当初一样的困惑，使用 SHUT_RDWR 来调用 shutdown 不是和 close 基本一样吗，都是关闭连接的读和写两个方向。</p>
<p>其实，这两个还是有差别的。</p>
<ol>
<li><strong>第一个差别：close 会关闭连接，并释放所有连接对应的资源，而 shutdown 并不会释放掉套接字和所有的资源。</strong></li>
<li><strong>第二个差别：close 存在引用计数的概念，并不一定导致该套接字不可用；shutdown 则不管引用计数，直接使得该套接字不可用，如果有别的进程企图使用该套接字，将会受到影响。</strong></li>
<li><strong>第三个差别：close 的引用计数导致不一定会发出 FIN 结束报文，而 shutdown 则总是会发出 FIN 结束报文，这在我们打算关闭连接通知对端的时候，是非常重要的。</strong></li>
</ol>
<h4 id="3-2-3-体会-close-和-shutdown-的差别"><a href="#3-2-3-体会-close-和-shutdown-的差别" class="headerlink" title="3.2.3 体会 close 和 shutdown 的差别"></a>3.2.3 <strong>体会</strong> <strong>close</strong> <strong>和</strong> <strong>shutdown</strong> <strong>的差别</strong></h4><p><img src="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/27.png" alt="27"></p>
<h3 id="3-3-连接无效：使用Keep-Alive还是应用心跳来检测？"><a href="#3-3-连接无效：使用Keep-Alive还是应用心跳来检测？" class="headerlink" title="3.3 连接无效：使用Keep-Alive还是应用心跳来检测？"></a>3.3 <strong>连接无效：使用Keep-Alive还是应用心跳来检测？</strong></h3><p>上一篇文章中，我们讲到了如何使用 close 和 shutdown 来完成连接的关闭，在大多数情况下，<strong>我们会优选 shutdown 来完成对连接一个方向的关闭，待对端处理完之后，再完成另外一个方向的关闭。</strong></p>
<h4 id="3-3-1-从一个例子开始"><a href="#3-3-1-从一个例子开始" class="headerlink" title="3.3.1 从一个例子开始"></a>3.3.1 <strong>从一个例子开始</strong></h4><p>让我们用一个例子开始今天的话题。</p>
<p>我之前做过一个基于 <code>NATS</code> 消息系统的项目，多个消息的提供者 （pub）和订阅者（sub）都连到 <code>NATS</code> 消息系统，通过这个系统来完成消息的投递和订阅处理。</p>
<p>突然有一天，线上报了一个故障，一个流程不能正常处理。经排查，发现消息正确地投递到了 <code>NATS</code> 服务端，但是消息订阅者没有收到该消息，也没能做出处理，导致流程没能进行下去。</p>
<p>通过观察消息订阅者后发现，消息订阅者到 <code>NATS</code> 服务端的连接虽然显示是“正常”的，但实际上，这个连接已经是无效的了。为什么呢？<strong>这是因为 <code>NATS</code> 服务器崩溃过，<code>NATS</code> 服务器和消息订阅者之间的连接中断 FIN 包，由于异常情况，没能够正常到达消息订阅者，这样造成的结果就是消息订阅者一直维护着一个“过时的”连接，不会收到 <code>NATS</code> 服务器发送来的消息。</strong></p>
<p>这个故障的根本原因在于，作为 <code>NATS</code> 服务器的客户端，消息订阅者没有及时对连接的有效性进行检测，这样就造成了问题。</p>
<h4 id="3-3-2-TCP-Keep-Alive-选项"><a href="#3-3-2-TCP-Keep-Alive-选项" class="headerlink" title="3.3.2 TCP Keep-Alive 选项"></a>3.3.2 <strong>TCP Keep-Alive</strong> <strong>选项</strong></h4><p>那么有没有办法开启类似的“轮询”机制，让 TCP 告诉我们，连接是不是“活着”的呢？</p>
<p>这就是 TCP 保持活跃机制所要解决的问题。实际上，TCP 有一个保持活跃的机制叫做Keep-Alive。</p>
<p>这个机制的原理是这样的：<strong>定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。</strong></p>
<p>上述的可定义变量，分别被称为保活时间、保活时间间隔和保活探测次数。在 Linux 系统中，这些变量分别对应 <code>sysctl</code> 变量<code>net.ipv4.tcp_keepalive_time、net.ipv4.tcp_keepalive_intvl、 net.ipv4.tcp_keepalve_probes</code>，默认设置是 7200 秒（2小时）、75 秒和 9 次探测。</p>
<p><strong>如果开启了 TCP 保活，需要考虑以下几种情况：</strong></p>
<ol>
<li><strong>第一种，对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 TCP 保活时间会被重置，等待下一个 TCP 保活时间的到来。</strong></li>
<li><strong>第二种，对端程序崩溃并重启。当 TCP 保活的探测报文发送给对端后，对端是可以响应的，但由于没有该连接的有效信息，会产生一个 RST 报文，这样很快就会发现 TCP 连接已经被重置。</strong></li>
<li><strong>第三种，是对端程序崩溃，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，TCP 会报告该TCP 连接已经死亡。</strong></li>
</ol>
<p>TCP 保活机制默认是关闭的，当我们选择打开时，可以分别在连接的两个方向上开启，也可以单独在一个方向上开启。如果开启服务器端到客户端的检测，就可以在客户端非正常断连的情况下清除在服务器端保留的“脏数据”；而开启客户端到服务器端的检测，就可以在服务器无响应的情况下，重新发起连接。</p>
<p>为什么 TCP 不提供一个频率很好的保活机制呢？我的理解是早期的网络带宽非常有限，如果提供一个频率很高的保活机制，对有限的带宽是一个比较严重的浪费。</p>
<h4 id="3-3-3-应用层探活"><a href="#3-3-3-应用层探活" class="headerlink" title="3.3.3 应用层探活"></a>3.3.3 <strong>应用层探活</strong></h4><p>如果使用 TCP 自身的 keep-Alive 机制，在 Linux 系统中，最少需要经过 2 小时 11 分 15 秒才可以发现一个“死亡”连接。这个时间是怎么计算出来的呢？其实是通过 2 小时，加上 75 秒乘以 9 的总和。实际上，对很多对时延要求敏感的系统中，这个时间间隔是不可接受的。所以，必须在应用程序这一层来寻找更好的解决方案。</p>
<p>我们可以通过在应用程序中模拟 TCP Keep-Alive 机制，来完成在应用层的连接探活。我们可以设计一个 <code>PING-PONG</code> 的机制，需要保活的一方，比如客户端，在保活时间达到后，发起对连接的 PING 操作，如果服务器端对 PING 操作有回应，则重新设置保活时间，否则对探测次数进行计数，如果最终探测次数达到了保活探测次数预先设置的值之后，则认为连接已经无效。</p>
<p>这里有两个比较关键的点：</p>
<p><strong>第一个是需要使用定时器，这可以通过使用 I/O 复用自身的机制来实现；第二个是需要设计一个 PING-PONG 的协议。</strong></p>
<p><em><strong><u>代码详见<code>PPT</code></u></strong></em></p>
<p>3.3.4 思考题</p>
<p>和往常一样，我留两道思考题给大家：</p>
<ol>
<li><strong>你可以看到今天的内容主要是针对 TCP 的探活，那么你觉得这样的方法是否同样适用于 UDP 呢？</strong></li>
<li><strong>第二道题是，有人说额外的探活报文占用了有限的带宽，对此你是怎么想的呢？而且，为什么需要多次探活才能决定一个 TCP 连接是否已经死亡呢？</strong></li>
</ol>
<p>评论区：</p>
<p>1.<code>UDP</code>里面各方并不会维护一个socket上下文状态是无连接的，如果为了连接而保活是不必要的，如果为了探测对端是否正常工作而做<code>ping-pong</code>也是可行的。</p>
<p>2.额外的探活报文是会占用一些带宽资源，可根据实际业务场景，适当增加保活时间，降低探活频率，简化<code>ping-pong</code>协议。 </p>
<p>3.多次探活是为了防止误伤，避免<code>ping</code>包在网络中丢失掉了，而误认为对端死亡。</p>
<h3 id="3-4-小数据包应对之策：理解TCP协议中的动态数据传输"><a href="#3-4-小数据包应对之策：理解TCP协议中的动态数据传输" class="headerlink" title="3.4 小数据包应对之策：理解TCP协议中的动态数据传输"></a>3.4 <strong>小数据包应对之策：理解TCP协议中的动态数据传输</strong></h3><p>如果你学过计算机网络的话，那么对于发送窗口、接收窗口、拥塞窗口等名词肯定不会陌生，它们各自解决的是什么问题，又是如何解决的？在今天的文章里，我希望能从一个更加通俗易懂的角度进行剖析。</p>
<p><strong>调用这些接口并不意味着数据被真正发送到网络上，其实，这些数据只是从应用程序中被拷贝到了系统内核的套接字缓冲区中，或者说是发送缓冲区中</strong>，等待协议栈的处理。至于这些数据是什么时候被发送出去的，对应用程序来说，是无法预知的。对这件事情真正负责的，是运行于操作系统内核的 TCP 协议栈实现模块。</p>
<h4 id="3-4-1-流量控制和生产者-消费者模型"><a href="#3-4-1-流量控制和生产者-消费者模型" class="headerlink" title="3.4.1 流量控制和生产者 - 消费者模型"></a>3.4.1 <strong>流量控制和生产者</strong> <strong>-</strong> <strong>消费者模型</strong></h4><p>发送窗口和接收窗口是 TCP 连接的双方，一个作为生产者，一个作为消费者，为了达到一致协同的生产 - 消费速率、而产生的算法模型实现。</p>
<p>说白了，作为 TCP 发送端，也就是生产者，不能忽略 TCP 的接收端，也就是<strong>消费者的实际状况，不管不顾地把数据包都传送过来。如果都传送过来，消费者来不及消费，必然会丢弃；而丢弃反过使得生产者又重传，发送更多的数据包，最后导致网络崩溃。</strong></p>
<p>我想，理解了“TCP 的生产者 - 消费者”模型，再反过来看发送窗口和接收窗口的设计目的和方式，我们就会恍然大悟了。</p>
<h4 id="3-4-2-拥塞控制和数据传输"><a href="#3-4-2-拥塞控制和数据传输" class="headerlink" title="3.4.2 拥塞控制和数据传输"></a>3.4.2 <strong>拥塞控制和数据传输</strong></h4><p>TCP 的生产者 - 消费者模型，只是在考虑单个连接的数据传递，但是， TCP 数据包是需要经过网卡、交换机、核心路由器等一系列的网络设备的，网络设备本身的能力也是有限的，当多个连接的数据包同时在网络上传送时，势必会发生带宽争抢、数据丢失等，这样，<strong>TCP就必须考虑多个连接共享在有限的带宽上，兼顾效率和公平性的控制</strong>，这就是拥塞控制的本质。</p>
<p>在 TCP 协议中，拥塞控制是通过拥塞窗口来完成的，拥塞窗口的大小会随着网络状况实时调整。</p>
<p>拥塞控制常用的算法有“慢启动”，它通过一定的规则，慢慢地将网络发送数据的速率增加到一个阈值。超过这个阈值之后，慢启动就结束了，另一个叫做“拥塞避免”的算法登场。在这个阶段，TCP 会不断地探测网络状况，并随之不断调整拥塞窗口的大小。</p>
<p>现在你可以发现，在任何一个时刻，TCP 发送缓冲区的数据是否能真正发送出去，<strong>至少</strong>取决于两个因素，一个<strong>当前的发送窗口大小</strong>，另一个是<strong>拥塞窗口大小</strong>，而 TCP 协议中总是<strong>取两者中最小值作为判断依据</strong>。比如当前发送的字节为 100，发送窗口的大小是 200，拥塞窗口的大小是 80，那么取 200 和 80 中的最小值，就是 80，当前发送的字节数显然是大于拥塞窗口的，结论就是不能发送出去。</p>
<p>这里千万要分清楚发送窗口和拥塞窗口的区别。</p>
<p><strong>发送窗口反应了作为单 TCP 连接、点对点之间的流量控制模型，它是需要和接收端一起共同协调来调整大小的；而拥塞窗口则是反应了作为多个 TCP 连接共享带宽的拥塞控制模型，它是发送端独立地根据网络状况来动态调整的。</strong></p>
<h4 id="3-4-3-一些有趣的场景"><a href="#3-4-3-一些有趣的场景" class="headerlink" title="3.4.3 一些有趣的场景"></a>3.4.3 <strong>一些有趣的场景</strong></h4><p>注意我在前面的表述中，提到了在任何一个时刻里，TCP 发送缓冲区的数据是否能真正发送出去，用了“至少两个因素”这个说法，细心的你有没有想过这个问题，<strong>除了之前引入的发送窗口、拥塞窗口之外，还有什么其他因素吗？</strong></p>
<p>第一个场景，接收端处理得急不可待，比如刚刚读入了 100 个字节，就告诉发送端：“喂，我已经读走 100 个字节了，你继续发”，在这种情况下，你觉得发送端应该怎么做呢？</p>
<p>第二个场景是所谓的“交互式”场景，比如我们使用 telnet 登录到一台服务器上，或者使用 SSH 和远程的服务器交互，这种情况下，我们在屏幕上敲打了一个命令，等待服务器返回结果，这个过程需要不断和服务器端进行数据传输。这里最大的问题是，每次传输的数据可能都非常小，比如敲打的命令“<code>pwd</code>”，仅仅三个字符。这意味着什么？这就好比，每次叫了一辆大货车，只送了一个小水壶。在这种情况下，你又觉得发送端该怎么做才合理呢？</p>
<p>第三个场景是从接收端来说的。我们知道，接收端需要对每个接收到的 TCP 分组进行确认，也就是发送 <code>ACK</code> 报文，但是 <code>ACK</code> 报文本身是不带数据的分段，如果一直这样发送大量的 <code>ACK</code> 报文，就会消耗大量的带宽。之所以会这样，是因为 TCP 报文、<code>IP</code> 报文固有的消息头是不可或缺的，比如两端的地址、端口号、时间戳、序列号等信息， 在这种情形下，你觉得合理的做法是什么？</p>
<p>TCP 之所以复杂，就是因为 TCP 需要考虑的因素较多。像以上这几个场景，都是 TCP 需要考虑的情况，一句话概况就是如何有效地利用网络带宽。</p>
<p>第一个场景也被叫做糊涂窗口综合症，这个场景需要在接收端进行优化。也就是说，<strong>接收端不能在接收缓冲区空出一个很小的部分之后，就急吼吼地向发送端发送窗口更新通知，而是需要在自己的缓冲区大到一个合理的值之后，再向发送端发送窗口更新通知。</strong>这个合理的值，由对应的 RFC 规范定义。</p>
<p>第二个场景需要在发送端进行优化。这个优化的算法叫做 <code>Nagle</code> 算法，<code>Nagle</code> 算法的本质其实就是限制大批量的小数据包同时发送，为此，它提出，<strong>在任何一个时刻，未被确认的小数据包不能超过一个。这里的小数据包，指的是长度小于最大报文段长度 <code>MSS</code> 的 TCP 分组。这样，发送端就可以把接下来连续的几个小数据包存储起来，等待接收到前一个小数据包的 <code>ACK</code> 分组之后，再将数据一次性发送出去。</strong></p>
<p>第三个场景，也是需要在接收端进行优化，这个优化的算法叫做延时 <code>ACK</code>。<strong>延时 <code>ACK</code> 在收到数据后并不马上回复，而是累计需要发送的 <code>ACK</code> 报文，等到有数据需要发送给对端时，将累计的 <code>ACK</code> 捎带一并发送出去。</strong>当然，延时 <code>ACK</code> 机制，不能无限地延时下去，否则发送端误认为数据包没有发送成功，引起重传，反而会占用额外的网络带宽。</p>
<h4 id="3-4-5-禁用-Nagle-算法"><a href="#3-4-5-禁用-Nagle-算法" class="headerlink" title="3.4.5 禁用 Nagle 算法"></a>3.4.5 <strong>禁用</strong> <strong><code>Nagle</code></strong> <strong>算法</strong></h4><p><img src="https://upload-images.jianshu.io/upload_images/12979420-f56600a05f27b88a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/741/format/webp" alt="img"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/12979420-702d5971c057c06e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/865/format/webp" alt="img"></p>
<p><em><strong>补充一篇博客讲解<code>nagle</code>和延迟确认算法的：</strong></em><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/da0cd673209c">【tcp/ip】TCP/IP 之 滑动窗口、Nagle算法和延迟确认 - 简书 (jianshu.com)</a></p>
<p>有没有发现一个很奇怪的组合，即 <strong><code>Nagle</code> 算法和延时 <code>ACK</code> 的组合。</strong></p>
<p>这个组合为什么奇怪呢？我举一个例子你来体会一下。</p>
<p>比如，客户端分两次将一个请求发送出去，由于请求的第一部分的报文未被确认，<code>Nagle</code> 算法开始起作用；同时延时 <code>ACK</code> 在服务器端起作用，假设延时时间为 <code>200ms</code>，服务器等待 <code>200ms</code> 后，对请求的第一部分进行确认；接下来客户端收到了确认后，<code>Nagle</code> 算法解除请求第二部分的阻止，让第二部分得以发送出去，服务器端在收到之后，进行处理应答，同时将第二部分的确认捎带发送出去。</p>
<h4 id="3-4-6-总结"><a href="#3-4-6-总结" class="headerlink" title="3.4.6 总结"></a>3.4.6 <strong>总结</strong></h4><p>今天的内容我重点讲述了 TCP 流量控制的生产者 - 消费者模型，<strong>你需要记住以下几点</strong>：</p>
<ol>
<li><strong>发送窗口用来控制发送和接收端的流量；阻塞窗口用来控制多条连接公平使用的有限带宽。</strong></li>
<li><strong>小数据包加剧了网络带宽的浪费，为了解决这个问题，引入了如 <code>Nagle</code> 算法、延时 <code>ACK</code> 等机制。</strong></li>
<li><strong>在程序设计层面，不要多次频繁地发送小报文，如果有，可以使用 <code>writev</code> 批量发送。</strong></li>
</ol>
<h3 id="3-5-UDP也可以是“已连接”？"><a href="#3-5-UDP也可以是“已连接”？" class="headerlink" title="3.5 UDP也可以是“已连接”？"></a>3.5 <strong><code>UDP</code>也可以是“已连接”？</strong></h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;lib/common.h&quot;</span></span></span><br><span class="line"><span class="meta"># <span class="keyword">define</span>    MAXLINE     4096</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> **argv)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (argc != <span class="number">2</span>) &#123;</span><br><span class="line">        <span class="built_in">error</span>(<span class="number">1</span>, <span class="number">0</span>, <span class="string">&quot;usage: udpclient1 &lt;IPaddress&gt;&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> socket_fd;</span><br><span class="line">    socket_fd = <span class="built_in">socket</span>(AF_INET, SOCK_DGRAM, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">sockaddr_in</span> server_addr;</span><br><span class="line">    <span class="built_in">bzero</span>(&amp;server_addr, <span class="built_in">sizeof</span>(server_addr));</span><br><span class="line">    server_addr.sin_family = AF_INET;</span><br><span class="line">    server_addr.sin_port = <span class="built_in">htons</span>(SERV_PORT);</span><br><span class="line">    <span class="built_in">inet_pton</span>(AF_INET, argv[<span class="number">1</span>], &amp;server_addr.sin_addr);</span><br><span class="line"></span><br><span class="line">    <span class="type">socklen_t</span> server_len = <span class="built_in">sizeof</span>(server_addr);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">connect</span>(socket_fd, (<span class="keyword">struct</span> sockaddr *) &amp;server_addr, server_len)) &#123;</span><br><span class="line">        <span class="built_in">error</span>(<span class="number">1</span>, errno, <span class="string">&quot;connect failed&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">sockaddr</span> *reply_addr;</span><br><span class="line">    reply_addr = <span class="built_in">malloc</span>(server_len);</span><br><span class="line"></span><br><span class="line">    <span class="type">char</span> send_line[MAXLINE], recv_line[MAXLINE + <span class="number">1</span>];</span><br><span class="line">    <span class="type">socklen_t</span> len;</span><br><span class="line">    <span class="type">int</span> n;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (<span class="built_in">fgets</span>(send_line, MAXLINE, stdin) != <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="type">int</span> i = <span class="built_in">strlen</span>(send_line);</span><br><span class="line">        <span class="keyword">if</span> (send_line[i - <span class="number">1</span>] == <span class="string">&#x27;\n&#x27;</span>) &#123;</span><br><span class="line">            send_line[i - <span class="number">1</span>] = <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;now sending %s\n&quot;</span>, send_line);</span><br><span class="line">        <span class="type">size_t</span> rt = <span class="built_in">sendto</span>(socket_fd, send_line, <span class="built_in">strlen</span>(send_line), <span class="number">0</span>, (<span class="keyword">struct</span> sockaddr *) &amp;server_addr, server_len);</span><br><span class="line">        <span class="keyword">if</span> (rt &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="built_in">error</span>(<span class="number">1</span>, errno, <span class="string">&quot;sendto failed&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;send bytes: %zu \n&quot;</span>, rt);</span><br><span class="line">        </span><br><span class="line">        len = <span class="number">0</span>;</span><br><span class="line">        recv_line[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">        n = <span class="built_in">recvfrom</span>(socket_fd, recv_line, MAXLINE, <span class="number">0</span>, reply_addr, &amp;len);</span><br><span class="line">        <span class="keyword">if</span> (n &lt; <span class="number">0</span>)</span><br><span class="line">            <span class="built_in">error</span>(<span class="number">1</span>, errno, <span class="string">&quot;recvfrom failed&quot;</span>);</span><br><span class="line">        recv_line[n] = <span class="number">0</span>;</span><br><span class="line">        <span class="built_in">fputs</span>(recv_line, stdout);</span><br><span class="line">        <span class="built_in">fputs</span>(<span class="string">&quot;\n&quot;</span>, stdout);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我对这个程序做一个简单的解释：</p>
<p>9-10 行创建了一个 <code>UDP</code> 套接字；</p>
<p>12-16 行创建了一个 <code>IPv4</code> 地址，绑定到指定端口和 <code>IP</code>；</p>
<p>**20-22 行调用 connect 将 <code>UDP</code> 套接字和 <code>IPv4</code> 地址进行了“绑定”，这里 <code>connect</code> 函数的名称有点让人误解，其实可能更好的选择是叫做 <code>setpeername</code>**；</p>
<p>31-55 行是程序的主体，读取标准输入字符串后，调用 <code>sendto</code> 发送给对端；之后调用 <code>recvfrom</code> 等待对端的响应，并把对端响应信息打印到标准输出。</p>
<h4 id="3-5-1-UDP-connect-的作用"><a href="#3-5-1-UDP-connect-的作用" class="headerlink" title="3.5.1 UDP connect 的作用"></a>3.5.1 <strong><code>UDP</code> connect</strong> <strong>的作用</strong></h4><p>从前面的例子中，你会发现，我们可以对 <code>UDP</code> 套接字调用 <code>connect</code> 函数，但是和 <code>TCP connect</code> 调用引起 TCP 三次握手，建立 TCP 有效连接不同，**<code>UDP connect</code> 函数的调用，并不会引起和服务器目标端的网络交互，也就是说，并不会触发所谓的”握手“报文发送和应答。**</p>
<p>那么对 <code>UDP</code> 套接字进行 connect 操作到底有什么意义呢？</p>
<p>其实上面的例子已经给出了答案，这主要是为了让应用程序能够接收”异步错误“的信息。如果我们回想一下第 6 篇不调用 connect 操作的客户端程序，在服务器端不开启的情况下，客户端程序是不会报错的，程序只会阻塞在 recvfrom 上，等待返回（或者超时）。</p>
<p>在这里，我们通过对 UDP 套接字进行 connect 操作，将 UDP 套接字建立了”上下文“，该套接字和服务器端的地址和端口产生了联系，正是这种绑定关系给了操作系统内核必要的信息，能够将操作系统内核收到的信息和对应的套接字进行关联。我们可以展开讨论一下。</p>
<p>事实上，当我们调用 sendto 或者 send 操作函数时，应用程序报文被发送，我们的应用程序返回，操作系统内核接管了该报文，之后操作系统开始尝试往对应的地址和端口发送，因为对应的地址和端口不可达，<strong>一个 ICMP 报文会返回给操作系统内核，该 ICMP 报文含有目的地址和端口等信息。</strong></p>
<p>如果我们不进行 connect 操作，建立（UDP 套接字——目的地址 + 端口）之间的映射关系，操作系统内核就没有办法把 ICMP 不可达的信息和 UDP 套接字进行关联，也就没有办法将 ICMP 信息通知给应用程序。</p>
<p><strong>如果我们进行了 connect 操作，帮助操作系统内核从容建立了（UDP 套接字——目的地址 + 端口）之间的映射关系，当收到一个 ICMP 不可达报文时，操作系统内核可以从映射表中找出是哪个 UDP 套接字拥有该目的地址和端口</strong>，别忘了套接字在操作系统内部是全局唯一的，当我们在该套接字上再次调用 recvfrom 或 recv 方法时，就可以收到操作系统内核返回的”Connection Refused“的信息。</p>
<h4 id="3-5-2-性能考虑"><a href="#3-5-2-性能考虑" class="headerlink" title="3.5.2 性能考虑"></a>3.5.2 <strong>性能考虑</strong></h4><p>一般来说，客户端通过 connect 绑定服务端的地址和端口，对 UDP 而言，可以有一定程度的性能提升。</p>
<p>这是为什么呢？</p>
<p><strong>因为如果不使用 connect 方式，每次发送报文都会需要这样的过程：</strong></p>
<p><strong>连接套接字→发送报文→断开套接字→连接套接字→发送报文→断开套接字 →………而如果使用 connect 方式，就会变成下面这样：</strong></p>
<p><strong>连接套接字→发送报文→发送报文→……→最后断开套接字</strong></p>
<p>我们知道，连接套接字是需要一定开销的，比如需要查找路由表信息。所以，UDP 客户端程序通过 connect 可以获得一定的性能提升。</p>
<h3 id="3-6-怎么老是出现“地址已经被使用”？"><a href="#3-6-怎么老是出现“地址已经被使用”？" class="headerlink" title="3.6 怎么老是出现“地址已经被使用”？"></a>3.6 怎么老是出现“地址已经被使用”？</h3><p>在实战中，你可能会经常碰到一个问题，当服务器端程序重启之后，总是碰到“Address in use”的报错信息，服务器程序不能很快地重启。那么这个问题是如何产生的？我们又该如何避免呢？</p>
<p>接下来，我们改变一下连接的关闭顺序。和前面的过程一样，先启动服务器，再使用 Telnet 作为客户端登录到服务器，在屏幕上输入一些字符。注意接下来的不同，我不会在 Telnet 端关闭连接，而是直接使用 Ctrl+C 的方式在服务器端关闭连接。</p>
<p>我们看到，连接已经被关闭，Telnet 客户端也感知连接关闭并退出了。接下来，我们尝试重启服务器端程序。你会发现，这个时候服务端程序重启失败，报错信息为：**<code>bind failed:Address already in use</code>**。</p>
<h4 id="3-6-1-复习-TIME-WAIT"><a href="#3-6-1-复习-TIME-WAIT" class="headerlink" title="3.6.1 复习 TIME_WAIT"></a>3.6.1 <strong>复习</strong> <strong>TIME_WAIT</strong></h4><p>还记得第 10 篇文章里提到的 TIME_WAIT 么？<strong>当连接的一方主动关闭连接，在接收到对端的 FIN 报文之后，主动关闭连接的一方会在 TIME_WAIT 这个状态里停留一段时间，这个时间大约为 <code>2MSL</code>。</strong></p>
<p>正是这个 TIME_WAIT 的连接，使得服务器重启时，继续绑定在 127.0.0.1 地址和 9527 端口上的操作，返回了<strong>Address already in use</strong>的错误</p>
<h4 id="3-6-2-重用套接字选项"><a href="#3-6-2-重用套接字选项" class="headerlink" title="3.6.2 重用套接字选项"></a>3.6.2 <strong>重用套接字选项</strong></h4><p>一个 TCP 连接是通过四元组（源地址、源端口、目的地址、目的端口）来唯一 确定的，如果每次 Telnet 客户端使用的本地端口都不同，就不会和已有的四元组冲突，也就不会有 TIME_WAIT 的新旧连接化身冲突的问题。</p>
<p>事实上，即使在很小的概率下，客户端 Telnet 使用了相同的端口，从而造成了新连接和旧连接的四元组相同，在现代 Linux 操作系统下，也不会有什么大的问题，原因是现代 Linux 操作系统对此进行了一些优化。</p>
<ol>
<li><strong>第一种优化是新连接 SYN 告知的初始序列号，一定比 TIME_WAIT 老连接的末序列号大，这样通过序列号就可以区别出新老连接。</strong></li>
<li><strong>第二种优化是开启了 tcp_timestamps，使得新连接的时间戳比老连接的时间戳大，这样通过时间戳也可以区别出新老连接。</strong></li>
</ol>
<p><em><strong>在这样的优化之下，一个 TIME_WAIT 的 TCP 连接可以忽略掉旧连接，重新被新的连接所使用。</strong></em></p>
<p>这就是重用套接字选项，通过给套接字配置可重用属性，告诉操作系统内核，这样的 TCP 连接完全可以复用 TIME_WAIT 状态的连接。代码片段已经放在文章中了：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> on = <span class="number">1</span>;</span><br><span class="line"><span class="built_in">setsockopt</span>(listenfd, SOL_SOCKET, SO_REUSEADDR, &amp;on, <span class="built_in">sizeof</span>(on));</span><br></pre></td></tr></table></figure>

<p><strong><code>SO_REUSEADDR</code> 套接字选项，允许启动绑定在一个端口，即使之前存在一个和该端口一样的连接。</strong>前面的例子已经表明，在默认情况下，服务器端历经创建 socket、bind 和 listen 重启时，如果试图绑定到一个现有连接上的端口，bind 操作会失败，但是如果我们在创建 socket 和 bind 之间，使用上面的代码片段设置 <code>SO_REUSEADDR</code> 套接字选项，情况就会不同。</p>
<p>重新编译过后，重复上面那个例子，先启动服务器，再使用 Telnet 作为客户端登录到服务器，在屏幕上输入一些字符，使用 Ctrl+C 的方式在服务器端关闭连接。马上尝试重启服务器，这个时候我们发现，服务器正常启动，没有出现<strong>Address already in use</strong>的错误。这说明我们的修改已经起作用。</p>
<h4 id="3-6-3-最佳实践"><a href="#3-6-3-最佳实践" class="headerlink" title="3.6.3 最佳实践"></a>3.6.3 <strong>最佳实践</strong></h4><p>这里的最佳实践可以总结成一句话： <strong>服务器端程序，都应该设置 <code>SO_REUSEADDR</code> 套接字选项，以便服务端程序可以在极短时间内复用同一个端口启动。</strong></p>
<p>有些人可能觉得这不是安全的。其实，单独重用一个套接字不会有任何问题。我在前面已经讲过，TCP 连接是通过四元组唯一区分的，只要客户端不使用相同的源端口，连接服务器是没有问题的，即使使用了相同的端口，根据序列号或者时间戳，也是可以区分出新旧连接的。</p>
<p>你可能还记得第 10 讲中，我们提到过一个叫做 tcp_tw_reuse 的内核配置选项，这里又提到了 SO_REUSEADDR 套接字选择，你会不会觉得两个有点混淆呢？</p>
<p>其实，这两个东西一点关系也没有。</p>
<ol>
<li><code>tcp_tw_reuse</code> 是内核选项，主要用在连接的发起方。<strong>TIME_WAIT 状态的连接创建时间超过 1 秒后，新的连接才可以被复用，注意，这里是连接的发起方</strong>；</li>
<li><code>SO_REUSEADDR</code> 是用户态的选项，<code>SO_REUSEADDR</code> 选项用来告诉操作系统内核，<strong>如果端口已被占用，但是 TCP 连接状态位于 TIME_WAIT ，可以重用端口。如果端口忙，而 TCP 处于其他状态，重用端口时依旧得到“Address already in use”的错误信息。</strong>注意，这里一般都是连接的服务方。</li>
</ol>
<h3 id="3-7-如何理解TCP的“流”？"><a href="#3-7-如何理解TCP的“流”？" class="headerlink" title="3.7 如何理解TCP的“流”？"></a>3.7 <strong>如何理解TCP的“流”？</strong></h3><h4 id="3-7-1-TCP-是一种流式协议"><a href="#3-7-1-TCP-是一种流式协议" class="headerlink" title="3.7.1 TCP 是一种流式协议"></a>3.7.1 <strong>TCP</strong> <strong>是一种流式协议</strong></h4><p>我们知道，在发送端，<strong>当我们调用 send 函数完成数据“发送”以后，数据并没有被真正从网络上发送出去，只是从应用程序拷贝到了操作系统内核协议栈中，至于什么时候真正被发送，取决于发送窗口、拥塞窗口以及当前发送缓冲区的大小等条件。</strong>也就是说，我们不能假设每次 send 调用发送的数据，都会作为一个整体完整地被发送出去。</p>
<p>实际上类似的组合可以枚举出无数种。不管是哪一种，核心的问题就是，我们不知道 network 和 program 这两个报文是如何进行 TCP 分组传输的。<strong>换言之，我们在发送数据的时候，不应该假设“数据流和 TCP 分组是一种映射关系”。就好像在前面，我们似乎觉得 network 这个报文一定对应一个 TCP 分组，这是完全不正确的。</strong></p>
<p>关于接收端字节流，有***<u>两点需要注意</u>***：</p>
<p>第一，这里 <code>netwrok</code> 和 <code>program</code> 的顺序肯定是会保持的，<strong>也就是说，先调用 send 函数发送的字节，总在后调用 send 函数发送字节的前面，这个是由 TCP 严格保证的；</strong></p>
<p>第二，<strong>如果发送过程中有 TCP 分组丢失，但是其后续分组陆续到达，那么 TCP 协议栈会缓存后续分组，直到前面丢失的分组到达，最终，形成可以被应用程序读取的数据流。</strong></p>
<h4 id="3-8-2-报文读取和解析"><a href="#3-8-2-报文读取和解析" class="headerlink" title="3.8.2 报文读取和解析"></a>3.8.2 <strong>报文读取和解析</strong></h4><p>应该看到，报文是以字节流的形式呈现给应用程序的，那么随之而来的一个问题就是，应用程序如何解读字节流呢？</p>
<p>这就要说到报文格式和解析了。报文格式实际上定义了字节的组织形式，发送端和接收端都按照统一的报文格式进行数据传输和解析，这样就可以保证彼此能够完成交流。</p>
<p>只有知道了报文格式，接收端才能针对性地进行报文读取和解析工作。</p>
<p>报文格式最重要的是如何确定报文的边界。<strong>常见的报文格式有两种方法，一种是发送端把要发送的报文长度预先通过报文告知给接收端；另一种是通过一些特殊的字符来进行边界的划分。</strong></p>
<h4 id="3-8-3-总结"><a href="#3-8-3-总结" class="headerlink" title="3.8.3 总结"></a>3.8.3 <strong>总结</strong></h4><p>和我们预想的不太一样，TCP 数据流特性决定了字节流本身是没有边界的，<strong>一般我们通过显式编码报文长度的方式，以及选取特殊字符区分报文边界的方式来进行报文格式的设计。而对报文解析的工作就是要在知道报文格式的情况下，有效地对报文信息进行还原。</strong></p>
<h3 id="3-9-TCP并不总是“可靠”的？"><a href="#3-9-TCP并不总是“可靠”的？" class="headerlink" title="3.9 TCP并不总是“可靠”的？"></a>3.9 <strong>TCP并不总是“可靠”的？</strong></h3><h4 id="3-9-1-TCP-是可靠的？"><a href="#3-9-1-TCP-是可靠的？" class="headerlink" title="3.9.1 TCP 是可靠的？"></a>3.9.1 <strong>TCP</strong> <strong>是可靠的？</strong></h4><p>从发送端来看，应用程序通过调用 send 函数发送的数据流总能可靠地到达接收端；而从接收端来看，总是可以把对端发送的数据流完整无损地传递给应用程序来处理。</p>
<p>前面我们已经了解，发送端通过调用 send 函数之后，数据流并没有马上通过网络传输出去，而是存储在套接字的发送缓冲区中，由网络协议栈决定何时发送、如何发送。当对应的数据发送给接收端，接收端回应 ACK，存储在发送缓冲区的这部分数据就可以删除了，<strong>但是，发送端并无法获取对应数据流的 ACK 情况，也就是说，发送端没有办法判断对端的接收方是否已经接收发送的数据流，如果需要知道这部分信息，就必须在应用层自己添加处理逻辑，例如显式的报文确认机制。</strong></p>
<p><strong>从接收端来说，也没有办法保证 ACK 过的数据部分可以被应用程序处理</strong>，因为数据需要接收端程序从接收缓冲区中拷贝，可能出现的状况是，<strong>已经 ACK 的数据保存在接收端缓冲区中，接收端处理程序突然崩溃了，这部分数据就没有办法被应用程序继续处理。</strong></p>
<p>你有没有发现，TCP 协议实现并没有提供给上层应用程序过多的异常处理细节，或者说，TCP 协议反映链路异常的能力偏弱。</p>
<p>TCP 连接建立之后，能感知 TCP 链路的方式是有限的，<strong>一种是以 read 为核心的读操作，另一种是以 write 为核心的写操作</strong>。接下来，我们就看下如何通过读写操作来感知异常情况，以及对应的处理方式。</p>
<h4 id="3-9-2-故障模式总结"><a href="#3-9-2-故障模式总结" class="headerlink" title="3.9.2 故障模式总结"></a>3.9.2 <strong>故障模式总结</strong></h4><p><img src="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/29.png" alt="29"></p>
<p><strong>第一类，是对端无 FIN 包发送出来的情况；第二类是对端有 FIN 包发送出来。</strong>而这两大类情况又可以根据应用程序的场景细分，接下来我们详细讨论。</p>
<h4 id="3-9-3-网络中断造成的对端无-FIN-包"><a href="#3-9-3-网络中断造成的对端无-FIN-包" class="headerlink" title="3.9.3 网络中断造成的对端无 FIN 包"></a>3.9.3 网络中断造成的对端无 FIN 包</h4><p>很多原因都会造成网络中断，在这种情况下，TCP 程序并不能及时感知到异常信息。除非网络中的其他设备，如路由器发出一条 ICMP 报文，说明目的网络或主机不可达，这个时候通过 read 或 write 调用就会返 Unreachable 的错误。</p>
<p>可惜大多数时候并不是如此，在没有 ICMP 报文的情况下，TCP 程序并不能理解感应到连接异常。<strong>如果程序是阻塞在 read 调用上，那么很不幸，程序无法从异常中恢复。这显然是非常不合理的，不过，我们可以通过给 read 操作设置超时来解决</strong>，在接下来的第 18 讲中，我会讲到具体的方法。</p>
<p><strong>如果程序先调用了 write 操作发送了一段数据流，接下来阻塞在 read 调用上</strong>，结果会非常不同。Linux 系统的 TCP 协议栈会不断尝试将发送缓冲区的数据发送出去，大概在重传 12 次、合计时间约为 9 分钟之后，协议栈会标识该连接异常，这时，阻塞的 read 调用会返回一条 TIMEOUT 的错误信息。如果此时程序还执着地往这条连接写数据，写操作会立即失败，返回一个 SIGPIPE 信号给应用程序。</p>
<h4 id="3-9-4-系统崩溃造成的对端无-FIN-包"><a href="#3-9-4-系统崩溃造成的对端无-FIN-包" class="headerlink" title="3.9.4 系统崩溃造成的对端无 FIN 包"></a>3.9.4 <strong>系统崩溃造成的对端无</strong> <strong>FIN</strong> <strong>包</strong></h4><p>当系统突然崩溃，如断电时，网络连接上来不及发出任何东西。这里和通过系统调用杀死应用程序非常不同的是，没有任何 FIN 包被发送出来。</p>
<p>这种情况和网络中断造成的结果非常类似，在没有 ICMP 报文的情况下，TCP 程序只能通过 read 和 write 调用得到网络连接异常的信息，超时错误是一个常见的结果。</p>
<p>不过还有一种情况需要考虑，那就是系统在崩溃之后又重启，<strong>当重传的 TCP 分组到达重启后的系统，由于系统中没有该 TCP 分组对应的连接数据，系统会返回一个 RST 重置分节，TCP 程序通过 read 或 write 调用可以分别对 RST 进行错误处理。</strong></p>
<p>如果是阻塞的 read 调用，会立即返回一个错误，错误信息为连接重置（Connection Resest）。</p>
<p>如果是一次 write 操作，也会立即失败，应用程序会被返回一个 SIGPIPE 信号</p>
<h4 id="3-9-5-对端有-FIN-包发出"><a href="#3-9-5-对端有-FIN-包发出" class="headerlink" title="3.9.5 对端有 FIN 包发出"></a>3.9.5 <strong>对端有</strong> <strong>FIN</strong> <strong>包发出</strong></h4><p>对端如果有 FIN 包发出，<strong>可能的场景是对端调用了 close 或 shutdown 显式地关闭了连接，也可能是对端应用程序崩溃</strong>，操作系统内核代为清理所发出的。从应用程序角度上看，无法区分是哪种情形。</p>
<p>阻塞的 read 操作在完成正常接收的数据读取之后，FIN 包会通过返回一个 EOF 来完成通知，此时，read 调用返回值为 0。<strong>这里强调一点，收到 FIN 包之后 read 操作不会立即返回。你可以这样理解，收到 FIN 包相当于往接收缓冲区里放置了一个 EOF 符号，之前已经在接收缓冲区的有效数据不会受到影响。</strong></p>
<p>为了展示这些特性，我分别编写了服务器端和客户端程序。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> <span class="comment">// 服务端程序</span></span><br><span class="line"><span class="number">2</span> <span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> **argv)</span> </span>&#123;</span><br><span class="line"><span class="number">3</span> 	<span class="type">int</span> connfd;</span><br><span class="line"><span class="number">4</span> 	<span class="type">char</span> buf[<span class="number">1024</span>];</span><br><span class="line"><span class="number">5</span></span><br><span class="line"><span class="number">6</span> 	connfd = <span class="built_in">tcp_server</span>(SERV_PORT);</span><br><span class="line"><span class="number">7</span></span><br><span class="line"><span class="number">8</span> 	<span class="keyword">for</span> (;;) &#123;</span><br><span class="line"><span class="number">9</span> 	<span class="type">int</span> n = <span class="built_in">read</span>(connfd, buf, <span class="number">1024</span>);</span><br><span class="line"><span class="number">10</span>  <span class="keyword">if</span> (n &lt; <span class="number">0</span>) &#123;</span><br><span class="line"><span class="number">11</span> 		<span class="built_in">error</span>(<span class="number">1</span>, errno, <span class="string">&quot;error read&quot;</span>);</span><br><span class="line"><span class="number">12</span> 	&#125; <span class="keyword">else</span> <span class="keyword">if</span> (n == <span class="number">0</span>) &#123;</span><br><span class="line"><span class="number">13</span> 		<span class="built_in">error</span>(<span class="number">1</span>, <span class="number">0</span>, <span class="string">&quot;client closed \n&quot;</span>);</span><br><span class="line"><span class="number">14</span> 	&#125;</span><br><span class="line"><span class="number">15</span></span><br><span class="line"><span class="number">16</span> 	<span class="built_in">sleep</span>(<span class="number">5</span>);</span><br><span class="line"><span class="number">17</span></span><br><span class="line"><span class="number">18</span> 	<span class="type">int</span> write_nc = <span class="built_in">send</span>(connfd, buf, n, <span class="number">0</span>);</span><br><span class="line"><span class="number">19</span> 	<span class="built_in">printf</span>(<span class="string">&quot;send bytes: %zu \n&quot;</span>, write_nc);</span><br><span class="line"><span class="number">20</span> 	<span class="keyword">if</span> (write_nc &lt; <span class="number">0</span>) &#123;</span><br><span class="line"><span class="number">21</span> 		<span class="built_in">error</span>(<span class="number">1</span>, errno, <span class="string">&quot;error write&quot;</span>);</span><br><span class="line"><span class="number">22</span> 	&#125;</span><br><span class="line"><span class="number">23</span> 	&#125;</span><br><span class="line"><span class="number">24</span></span><br><span class="line"><span class="number">25</span> 	<span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line"><span class="number">26</span> &#125;</span><br></pre></td></tr></table></figure>

<p>服务端程序是一个简单的应答程序，在收到数据流之后回显给客户端，在此之前，休眠 5 秒，以便完成后面的实验验证。</p>
<p>客户端程序从标准输入读入，将读入的字符串传输给服务器端：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> <span class="comment">// 客户端程序</span></span><br><span class="line"><span class="number">2</span> <span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> **argv)</span> </span>&#123;</span><br><span class="line"><span class="number">3</span> 	<span class="keyword">if</span> (argc != <span class="number">2</span>) &#123;</span><br><span class="line"><span class="number">4</span> 	<span class="built_in">error</span>(<span class="number">1</span>, <span class="number">0</span>, <span class="string">&quot;usage: reliable_client01 &lt;IPaddress&gt;&quot;</span>);</span><br><span class="line"><span class="number">5</span> &#125;</span><br><span class="line"><span class="number">6</span></span><br><span class="line"><span class="number">7</span> 	<span class="type">int</span> socket_fd = <span class="built_in">tcp_client</span>(argv[<span class="number">1</span>], SERV_PORT);</span><br><span class="line"><span class="number">8</span> 	<span class="type">char</span> buf[<span class="number">128</span>];</span><br><span class="line"><span class="number">9</span> 	<span class="type">int</span> len;</span><br><span class="line"><span class="number">10</span> 	<span class="type">int</span> rc;</span><br><span class="line"><span class="number">11</span></span><br><span class="line"><span class="number">12</span> 	<span class="keyword">while</span> (<span class="built_in">fgets</span>(buf, <span class="built_in">sizeof</span>(buf), stdin) != <span class="literal">NULL</span>) &#123;</span><br><span class="line"><span class="number">13</span> 		len = <span class="built_in">strlen</span>(buf);</span><br><span class="line"><span class="number">14</span> 		rc = <span class="built_in">send</span>(socket_fd, buf, len, <span class="number">0</span>);</span><br><span class="line"><span class="number">15</span> 		<span class="keyword">if</span> (rc &lt; <span class="number">0</span>)</span><br><span class="line"><span class="number">16</span> 			<span class="built_in">error</span>(<span class="number">1</span>, errno, <span class="string">&quot;write failed&quot;</span>);</span><br><span class="line"><span class="number">17</span> 		rc = <span class="built_in">read</span>(socket_fd, buf, <span class="built_in">sizeof</span>(buf));</span><br><span class="line"><span class="number">18</span> 		<span class="keyword">if</span> (rc &lt; <span class="number">0</span>)</span><br><span class="line"><span class="number">19</span> 			<span class="built_in">error</span>(<span class="number">1</span>, errno, <span class="string">&quot;read failed&quot;</span>);</span><br><span class="line"><span class="number">20</span> 		<span class="keyword">else</span> <span class="keyword">if</span> (rc == <span class="number">0</span>)</span><br><span class="line"><span class="number">21</span> 			<span class="built_in">error</span>(<span class="number">1</span>, <span class="number">0</span>, <span class="string">&quot;peer connection closed\n&quot;</span>);</span><br><span class="line"><span class="number">22</span> 		<span class="keyword">else</span></span><br><span class="line"><span class="number">23</span> 			<span class="built_in">fputs</span>(buf, stdout);</span><br><span class="line"><span class="number">24</span> 	&#125;</span><br><span class="line"><span class="number">25</span> 	<span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line"><span class="number">26</span> &#125;</span><br></pre></td></tr></table></figure>

<h4 id="3-9-6-read-直接感知-FIN-包"><a href="#3-9-6-read-直接感知-FIN-包" class="headerlink" title="3.9.6 read 直接感知 FIN 包"></a>3.9.6 read 直接感知 FIN 包</h4><p>我们依次启动服务器端和客户端程序，在客户端输入 good 字符之后，迅速结束掉服务器端程序，这里需要赶在服务器端从睡眠中苏醒之前杀死服务器程序。</p>
<p><strong>这说明客户端程序通过 read 调用，感知到了服务端发送的 FIN 包，于是正常退出了客户端程序。</strong></p>
<p><img src="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/30.png" alt="30"></p>
<p>注意如果我们的速度不够快，导致服务器端从睡眠中苏醒，并成功将报文发送出来后，客户端会正常显示，此时我们停留，等待标准输入。<strong>如果不继续通过 read 或 write 操作对套接字进行读写，是无法感知服务器端已经关闭套接字这个事实的。</strong></p>
<h4 id="3-9-7-通过-write-产生-RST，read-调用感知-RST"><a href="#3-9-7-通过-write-产生-RST，read-调用感知-RST" class="headerlink" title="3.9.7 通过 write 产生 RST，read 调用感知 RST"></a>3.9.7 <strong>通过</strong> <strong>write</strong> <strong>产生</strong> <strong>RST</strong>，<strong>read</strong> <strong>调用感知</strong> <strong>RST</strong></h4><p>这一次，我们仍然依次启动服务器端和客户端程序，在客户端输入 bad 字符之后，等待一段时间，直到客户端正确显示了服务端的回应“bad”字符之后，再杀死服务器程序。客户端再次输入 bad2，这时屏幕上打印出”peer connection closed“。</p>
<p>我在文稿中给出了这个案例的屏幕输出和时序图。</p>
<p><img src="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/30.png" alt="30"></p>
<p>在很多书籍和文章中，对这个程序的解读是，<strong>收到 FIN 包的客户端继续合法地向服务器端发送数据，服务器端在无法定位该 TCP 连接信息的情况下，发送了 RST 信息，当程序调用 read 操作时，内核会将 RST 错误信息通知给应用程序。</strong>这是一个典型的 write 操作造成异常，再通过 read 操作来感知异常的样例。</p>
<p>不过，我在 Linux 4.4 内核上实验这个程序，多次的结果都是，内核正常将 EOF 信息通知给应用程序，而不是 RST 错误信息。</p>
<h4 id="3-9-8-向一个已关闭连接连续写，最终导致-SIGPIPE"><a href="#3-9-8-向一个已关闭连接连续写，最终导致-SIGPIPE" class="headerlink" title="3.9.8 向一个已关闭连接连续写，最终导致 SIGPIPE"></a>3.9.8 <strong>向一个已关闭连接连续写，最终导致</strong> <strong>SIGPIPE</strong></h4><p>这是因为服务端程序被杀死之后，操作系统内核会做一些清理的事情，为这个套接字发送一个 FIN 包，但是，客户端在收到 FIN 包之后，没有 read 操作，还是会继续往这个套接字写入数据。这是因为根据 TCP 协议，连接是双向的，收到对方的 FIN 包只意味着<strong>对方不会再发送任何消息</strong>。 在一个双方正常关闭的流程中，收到 FIN 包的一端将剩余数据发送给对面（通过一次或多次 write），然后关闭套接字。</p>
<p>当数据到达服务器端时，操作系统内核发现这是一个指向关闭的套接字，会再次向客户端发送一个 RST 包，对于发送端而言如果此时再执行 write 操作，立即会返回一个 RST 错误信息。</p>
<p>你可以看到针对这个全过程的一张描述图，你可以参考这张图好好理解一下这个过程。</p>
<p><img src="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/31.png" alt="31"></p>
<p>在很多书籍和文章中，对这个实验的期望结果不是这样的。大部分的教程是这样说的：在第二次 write 操作时，由于服务器端无法查询到对应的 TCP 连接信息，于是发送了一个 RST 包给客户端，客户端第二次操作时，应用程序会收到一个 SIGPIPE 信号。如果不捕捉这个信号，应用程序会在毫无征兆的情况下直接退出。</p>
<h4 id="3-9-9-总结"><a href="#3-9-9-总结" class="headerlink" title="3.9.9 总结"></a>3.9.9 <strong>总结</strong></h4><p>在这一讲中，我们意识到 TCP 并不是那么“可靠”的。我把故障分为两大类，一类是对端无 FIN 包，需要通过巡检或超时来发现；另一类是对端有 FIN 包发出，需要通过增强 read 或 write 操作的异常处理，帮助我们发现此类异常。</p>
<h3 id="3-10-防人之心不可无：检查数据的有效性"><a href="#3-10-防人之心不可无：检查数据的有效性" class="headerlink" title="3.10 防人之心不可无：检查数据的有效性"></a>3.10 <strong>防人之心不可无：检查数据的有效性</strong></h3><h2 id="4-性能篇"><a href="#4-性能篇" class="headerlink" title="4 性能篇"></a>4 性能篇</h2><h3 id="4-1-大名⿍⿍的select：看我如何同时感知多个I-O事件"><a href="#4-1-大名⿍⿍的select：看我如何同时感知多个I-O事件" class="headerlink" title="4.1 大名⿍⿍的select：看我如何同时感知多个I/O事件"></a>4.1 <strong>大名⿍⿍的select：看我如何同时感知多个I/O事件</strong></h3><p>这一讲是性能篇的第一讲。在性能篇里，我们将把注意力放到如何设计高并发高性能的网络服务器程序上。我希望通过这一模块的学习，让你能够掌握多路复用、异步 I/O、多线程等知识，从而可以写出支持并发 10K 以上的高性能网络服务器程序。</p>
<h4 id="4-1-1-什么是-I-O-多路复用"><a href="#4-1-1-什么是-I-O-多路复用" class="headerlink" title="4.1.1 什么是 I/O 多路复用"></a>4.1.1 <strong>什么是</strong> <strong>I/O</strong> <strong>多路复用</strong></h4><p>我们可以使用 fgets 方法等待标准输入，但是一旦这样做，就没有办法在套接字有数据的时候读出数据；我们也可以使用 read 方法等待套接字有数据返回，但是这样做，也没有办法在标准输入有数据的情况下，读入数据并发送给对方。</p>
<p>I/O 多路复用的设计初衷就是解决这样的场景。<strong>我们可以把标准输入、套接字等都看做 I/O 的一路，多路复用的意思，就是在任何一路 I/O 有“事件”发生的情况下，通知应用程序去处理相应的 I/O 事件，这样我们的程序就变成了“多面手”，在同一时刻仿佛可以处理多个 I/O 事件。</strong></p>
<p>像刚才的例子，使用 I/O 复用以后，如果标准输入有数据，立即从标准输入读入数据，通过套接字发送出去；如果套接字有数据可以读，立即可以读出数据。</p>
<p>select 函数就是这样一种常见的 I/O 多路复用技术，我们将在后面继续讲解其他的多路复用技术。使用 select 函数，通知内核挂起进程，当一个或多个 I/O 事件发生后，控制权返还给应用程序，由应用程序进行 I/O 事件的处理。</p>
<p>这些 <strong>I/O 事件</strong>的类型非常多，比如：</p>
<ol>
<li><strong>标准输入文件描述符准备好可以读。</strong></li>
<li><strong>监听套接字准备好，新的连接已经建立成功。</strong></li>
<li><strong>已连接套接字准备好可以写。</strong></li>
<li><strong>如果一个 I/O 事件等待超过了 10 秒，发生了超时事件。</strong></li>
</ol>
<h4 id="4-1-2-select-函数的使用方法"><a href="#4-1-2-select-函数的使用方法" class="headerlink" title="4.1.2 select 函数的使用方法"></a>4.1.2 <strong>select</strong> <strong>函数的使用方法</strong></h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">select</span><span class="params">(<span class="type">int</span> maxfd, fd_set *readset, fd_set *writeset, fd_set *exceptset, <span class="type">const</span> <span class="keyword">struct</span></span></span></span><br></pre></td></tr></table></figure>

<p>在这个函数中，n 表示的是待测试的描述符基数，它的值是待测试的最大描述符加 1。比如现在的 select 待测试的描述符集合是{0,1,4}，那么 maxfd 就是 5，为啥是 5，而不是 4呢? 我会在下面进行解释。</p>
<p>紧接着的是三个描述符集合，分别是读描述符集合 readset、写描述符集合 writeset 和异常描述符集合 exceptset，<strong>这三个分别通知内核，在哪些描述符上检测数据可以读，可以写和有异常发生。</strong></p>
<p>那么如何设置这些描述符集合呢？以下的宏可以帮助到我们。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> <span class="function"><span class="type">void</span> <span class="title">FD_ZERO</span><span class="params">(fd_set *fdset)</span></span>; </span><br><span class="line"><span class="number">2</span> <span class="function"><span class="type">void</span> <span class="title">FD_SET</span><span class="params">(<span class="type">int</span> fd, fd_set *fdset)</span></span>; </span><br><span class="line"><span class="number">3</span> <span class="function"><span class="type">void</span> <span class="title">FD_CLR</span><span class="params">(<span class="type">int</span> fd, fd_set *fdset)</span></span>; </span><br><span class="line"><span class="number">4</span> <span class="function"><span class="type">int</span> <span class="title">FD_ISSET</span><span class="params">(<span class="type">int</span> fd, fd_set *fdset)</span></span>;</span><br></pre></td></tr></table></figure>

<p>如果你刚刚入门，理解这些宏可能有些困难。没有关系，我们可以这样想象，下面一个向量代表了一个描述符集合，其中，这个向量的每个元素都是二机制数中的 0 或者 1。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a[maxfd<span class="number">-1</span>], ..., a[<span class="number">1</span>], a[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>

<p>我们按照这样的思路来理解这些宏：</p>
<ol>
<li>FD_ZERO 用来将这个向量的所有元素都设置成 0；</li>
<li>FD_SET 用来把对应套接字 fd 的元素，a[fd] 设置成 1；</li>
<li>FD_CLR 用来把对应套接字 fd 的元素，a[fd] 设置成 0；</li>
<li>FD_ISSET 对这个向量进行检测，判断出对应套接字的元素 a[fd] 是 0 还是 1。</li>
</ol>
<p>其中 0 代表不需要处理，1 代表需要处理。</p>
<p>这个时候再来理解为什么描述字集合{0,1,4}，对应的 maxfd 是 5，而不是 4，就比较方便了。</p>
<p>因为这个向量对应的是下面这样的：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a[<span class="number">4</span>],a[<span class="number">3</span>],a[<span class="number">2</span>],a[<span class="number">1</span>],a[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>

<p>待测试的描述符个数显然是 5， 而不是 4。</p>
<p>三个描述符集合中的每一个都可以设置成空，这样就表示不需要内核进行相关的检测。</p>
<p>最后一个参数是 timeval 结构体时间：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> <span class="keyword">struct</span> <span class="title class_">timeval</span> &#123;</span><br><span class="line"><span class="number">2</span> <span class="type">long</span> tv_sec; <span class="comment">/* seconds */</span></span><br><span class="line"><span class="number">3</span> <span class="type">long</span> tv_usec; <span class="comment">/* microseconds */</span></span><br><span class="line"><span class="number">4</span> &#125;;</span><br></pre></td></tr></table></figure>

<p>第一个可能是设置成空 (NULL)，表示如果没有 I/O 事件发生，则 select 一直等待下去。</p>
<p>第二个可能是设置一个非零的值，这个表示等待固定的一段时间后从 select 阻塞调用中返回。</p>
<p>第三个可能是将 tv_sec 和 tv_usec 都设置成 0，表示根本不等待，检测完毕立即返回。这种情况使用得比较少。</p>
<h4 id="4-1-3-套接字描述符就绪条件"><a href="#4-1-3-套接字描述符就绪条件" class="headerlink" title="4.1.3 套接字描述符就绪条件"></a>4.1.3 <strong>套接字描述符就绪条件</strong></h4><p>当我们说 select 测试返回，某个套接字准备好可读，表示什么样的事件发生呢？</p>
<ol>
<li><strong>第一种情况是套接字接收缓冲区有数据可以读，如果我们使用 read 函数去执行读操作，肯定不会被阻塞，而是会直接读到这部分数据。</strong></li>
<li><strong>第二种情况是对方发送了 FIN，使用 read 函数执行读操作，不会被阻塞，直接返回 0。</strong></li>
<li><strong>第三种情况是针对一个监听套接字而言的，有已经完成的连接建立，此时使用 accept 函数去执行不会阻塞，直接返回已经完成的连接。</strong></li>
<li><strong>第四种情况是套接字有错误待处理，使用 read 函数去执行读操作，不阻塞，且返回 -1。</strong></li>
</ol>
<p>总结成一句话就是，<strong>内核通知我们套接字有数据可以读了，使用 read 函数不会阻塞。</strong></p>
<p>不知道你是不是和我一样，刚开始理解某个套接字可写的时候，会有一个错觉，总是从应用程序角度出发去理解套接字可写，我开始是这样想的，当应用程序完成相应的计算，有数据准备发送给对端了，可以往套接字写，对应的就是套接字可写。</p>
<p>其实这个理解是非常不正确的，select 检测套接字可写，<strong>完全是基于套接字本身的特性来说</strong>的，具体来说有以下几种情况。</p>
<ol>
<li><strong>第一种是套接字发送缓冲区足够大，如果我们使用非阻塞套接字进行 write 操作，将不会被阻塞，直接返回。</strong></li>
<li><strong>第二种是连接的写半边已经关闭，如果继续进行写操作将会产生 SIGPIPE 信号。</strong></li>
<li><strong>第三种是套接字上有错误待处理，使用 write 函数去执行读操作，不阻塞，且返回 -1。</strong></li>
</ol>
<p>总结成一句话就是，<strong>内核通知我们套接字可以往里写了，使用 write 函数就不会阻塞。</strong></p>
<p><em><strong><u>代码详见PPT</u></strong></em></p>
<h3 id="4-2-poll：另一种I-O多路复用"><a href="#4-2-poll：另一种I-O多路复用" class="headerlink" title="4.2 poll：另一种I/O多路复用"></a>4.2 <strong>poll：另一种I/O多路复用</strong></h3><p>上一讲我们讲到了 I/O 多路复用技术，并以 select 为核心，展示了 I/O 多路复用技术的能力。<strong>select 方法是多个 UNIX 平台支持的非常常见的 I/O 多路复用技术，它通过描述符集合来表示检测的 I/O 对象，通过三个不同的描述符集合来描述 I/O 事件 ：可读、可写和异常。但是 select 有一个缺点，那就是所支持的文件描述符的个数是有限的。</strong>在 Linux 系统中，select 的默认最大值为 1024。</p>
<h4 id="4-2-1-poll-函数介绍"><a href="#4-2-1-poll-函数介绍" class="headerlink" title="4.2.1 poll 函数介绍"></a>4.2.1 <strong>poll</strong> <strong>函数介绍</strong></h4><p>poll 是除了 select 之外，另一种普遍使用的 I/O 多路复用技术，和 select 相比，它和内核交互的数据结构有所变化，另外，也突破了文件描述符的个数限制。</p>
<p>下面是 poll 函数的原型：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> <span class="function"><span class="type">int</span> <span class="title">poll</span><span class="params">(<span class="keyword">struct</span> pollfd *fds, <span class="type">unsigned</span> <span class="type">long</span> nfds, <span class="type">int</span> timeout)</span></span>; </span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">3</span> 返回值：若有就绪描述符则为其数目，若超时则为 <span class="number">0</span>，若出错则为 <span class="number">-1</span></span><br></pre></td></tr></table></figure>

<p>这个函数里面输入了三个参数，第一个参数是一个 pollfd 的数组。其中 pollfd 的结构如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> <span class="keyword">struct</span> <span class="title class_">pollfd</span> &#123;</span><br><span class="line"><span class="number">2</span> 	<span class="type">int</span> fd; <span class="comment">/* file descriptor */</span></span><br><span class="line"><span class="number">3</span> 	<span class="type">short</span> events; <span class="comment">/* events to look for */</span></span><br><span class="line"><span class="number">4</span> 	<span class="type">short</span> revents; <span class="comment">/* events returned */</span></span><br><span class="line"><span class="number">5</span> &#125;;</span><br></pre></td></tr></table></figure>

<p>这个结构体由三个部分组成，首先是描述符 fd，然后是描述符上待检测的事件类型 events，注意这里的 events 可以表示多个不同的事件，具体的实现可以通过使用二进制掩码位操作来完成，例如，POLLIN 和 POLLOUT 可以表示读和写事件。</p>
<p>最后一个参数 timeout，描述了 poll 的行为。如果是一个 &lt;0 的数，表示在有事件发生之前永远等待；如果是 0，表示不阻塞进程，立即返回；如果是一个 &gt;0 的数，表示 poll 调用方等待指定的毫秒数后返回。关于返回值，当有错误发生时，poll 函数的返回值为 -1；如果在指定的时间到达之前没有任何事件发生，则返回 0，否则就返回检测到的事件个数，也就是“returned events”中非 0 的描述符个数。</p>
<p>poll 函数有一点非常好，如果我们<strong>不想对某个 pollfd 结构进行事件检测，</strong>可以把它对应的 pollfd 结构的 fd 成员设置成一个负值。这样，poll 函数将忽略这样的 events 事件，检测完成以后，所对应的“returned events”的成员值也将设置为 0。</p>
<p>和 select 函数对比一下，我们发现 poll 函数和 select 不一样的地方就是，在 select 里面，文件描述符的个数已经随着 fd_set 的实现而固定，没有办法对此进行配置；而在 poll函数里，我们可以控制 pollfd 结构的数组大小，这意味着我们可以突破原来 select 函数最大描述符的限制，在这种情况下，应用程序调用者需要分配 pollfd 数组并通知 poll 函数该数组的大小。</p>
<p><em><strong><u>代码详见PPT</u></strong></em></p>
<h3 id="4-3-非阻塞I-O：提升性能的加速器"><a href="#4-3-非阻塞I-O：提升性能的加速器" class="headerlink" title="4.3 非阻塞I/O：提升性能的加速器"></a>4.3 <strong>非阻塞I/O：提升性能的加速器</strong></h3><p>在性能篇的前两讲中，我分别介绍了 select 和 poll 两种不同的 I/O 多路复用技术。在接下来的这一讲中，我将带大家进入非阻塞 I/O 模式的世界。事实上，<strong>非阻塞 I/O 配合 I/O 多路复用，是高性能网络编程中的常见技术。</strong></p>
<h4 id="4-3-1-阻塞-VS-非阻塞"><a href="#4-3-1-阻塞-VS-非阻塞" class="headerlink" title="4.3.1 阻塞 VS 非阻塞"></a>4.3.1 <strong>阻塞</strong> <strong>VS</strong> <strong>非阻塞</strong></h4><p>当应用程序调用阻塞 I/O 完成某个操作时，应用程序会被挂起，等待内核完成操作，感觉上应用程序像是被“阻塞”了一样。实际上，<strong>内核所做的事情是将 CPU 时间切换给其他有需要的进程，网络应用程序在这种情况下就会得不到 CPU 时间做该做的事情。</strong></p>
<p>非阻塞 I/O 则不然，当应用程序调用非阻塞 I/O 完成某个操作时，<strong>内核立即返回，不会把 CPU 时间切换给其他进程，应用程序在返回后，可以得到足够的 CPU 时间继续完成其他事情</strong>。</p>
<p><strong>但轮询的效率太低了，于是你向老板提议：“老板，到货给我打电话吧，我再来付钱取书。”这就是前面讲到的 I/O 多路复用。</strong></p>
<p>再进一步，你连去书店取书也想省了，得了，让老板代劳吧，你留下地址，付了书费，让老板到货时寄给你，你直接在家里拿到就可以看了。这就是我们将会在第 30 讲中讲到的异步I/O。</p>
<p>这几个 I/O 模型，再加上进程、线程模型，构成了整个网络编程的知识核心。</p>
<h4 id="4-3-2-非阻塞-I-O"><a href="#4-3-2-非阻塞-I-O" class="headerlink" title="4.3.2 非阻塞 I/O"></a>4.3.2 <strong>非阻塞</strong> <strong>I/O</strong></h4><p><strong>（1）读操作</strong></p>
<p>如果套接字对应的接收缓冲区没有数据可读，在非阻塞情况下 read 调用会立即返回，一般返回 EWOULDBLOCK 或 EAGAIN 出错信息。在这种情况下，出错信息是需要小心处理，比如后面再次调用 read 操作，而不是直接作为错误直接返回。这就好像去书店买书没买到离开一样，需要不断进行又一次轮询处理。</p>
<p><strong>（2）写操作</strong></p>
<p>不知道你有没有注意到，在阻塞 I/O 情况下，write 函数返回的字节数，和输入的参数总是一样的。如果返回值总是和输入的数据大小一样，write 等写入函数还需要定义返回值吗？我不知道你是不是和我一样，刚接触到这一部分知识的时候有这种困惑。</p>
<p>这里就要引出我们所说的非阻塞 I/O。在非阻塞 I/O 的情况下，如果套接字的发送缓冲区已达到了极限，不能容纳更多的字节，那么操作系统内核会<strong>尽最大可能</strong>从应用程序拷贝数据到发送缓冲区中，并立即从 write 等函数调用中返回。<strong>可想而知，在拷贝动作发生的瞬间，有可能一个字符也没拷贝，有可能所有请求字符都被拷贝完成，那么这个时候就需要返回一个数值，告诉应用程序到底有多少数据被成功拷贝到了发送缓冲区中，应用程序需要再次调用write 函数，以输出未完成拷贝的字节。</strong></p>
<p>write 等函数是可以同时作用到阻塞 I/O 和非阻塞 I/O 上的，为了复用一个函数，处理非阻塞和阻塞 I/O 多种情况，设计出了写入返回值，并用这个返回值表示实际写入的数据大小。</p>
<p>也就是说，非阻塞 I/O 和阻塞 I/O 处理的方式是不一样的。</p>
<p>非阻塞 I/O 需要这样：拷贝→返回→再拷贝→再返回。</p>
<p>而阻塞 I/O 需要这样：拷贝→直到所有数据拷贝至发送缓冲区完成→返回。</p>
<p>不过在实战中，你可以不用区别阻塞和非阻塞 I/O，使用循环的方式来写入数据就好了。只不过在阻塞 I/O 的情况下，循环只执行一次就结束了。</p>
<p><img src="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/32.png" alt="32"></p>
<p><img src="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/33.png" alt="33"></p>
<h4 id="4-3-3-总结"><a href="#4-3-3-总结" class="headerlink" title="4.3.3 总结"></a>4.3.3 <strong>总结</strong></h4><p><strong>非阻塞 I/O 可以使用在 read、write、accept、connect 等多种不同的场景，在非阻塞 I/O 下，使用轮询的方式引起 CPU 占用率高，所以一般将非阻塞 I/O 和 I/O 多路复用技术 select、poll 等搭配使用，在非阻塞 I/O 事件发生时，再调用对应事件的处理函数。</strong>这种方式，极大地提高了程序的健壮性和稳定性，是 Linux 下高性能网络编程的首选。</p>
<h3 id="4-4-Linux利器：epoll的前世今生"><a href="#4-4-Linux利器：epoll的前世今生" class="headerlink" title="4.4 Linux利器：epoll的前世今生"></a>4.4 <strong>Linux利器：epoll的前世今生</strong></h3><p>性能篇的前三讲，非阻塞 I/O 加上 I/O 多路复用，已经渐渐帮助我们在高性能网络编程这 个领域搭建了初步的基石。但是，离最终的目标还差那么一点，如果说 I/O 多路复用帮我们打开了高性能网络编程的窗口，那么今天的主题——epoll，将为我们增添足够的动力。</p>
<p>从图中可以明显地看到，<strong>epoll 的性能是最好的，即使在多达 10000 个文件描述的情况下，其性能的下降和有 10 个文件描述符的情况相比，差别也不是很大。而随着文件描述符的增大，常规的 select 和 poll 方法性能逐渐变得很差。</strong></p>
<h4 id="4-4-1-epoll-的用法"><a href="#4-4-1-epoll-的用法" class="headerlink" title="4.4.1 epoll 的用法"></a><strong>4.4.1 epoll 的用法</strong></h4><p>epoll 可以说是和 poll 非常相似的一种 I/O 多路复用技术，有些朋友将 epoll 归为异步 I/O，我觉得这是不正确的。本质上 epoll 还是一种 I/O 多路复用技术， epoll 通过监控注册的多个描述字，来进行 I/O 事件的分发处理。<strong>不同于 poll 的是，epoll 不仅提供了默认的 level-triggered（条件触发）机制，还提供了性能更为强劲的 edge-triggered（边缘触发）机制。至于这两种机制的区别，我会在后面详细展开。</strong></p>
<p>使用 epoll 进行网络程序的编写，需要三个步骤，分别是 epoll_create，epoll_ctl 和 epoll_wait。接下来我对这几个 API 详细展开讲一下。</p>
<h4 id="4-4-2-epoll-create"><a href="#4-4-2-epoll-create" class="headerlink" title="4.4.2 epoll_create"></a>4.4.2 <strong>epoll_create</strong></h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> <span class="function"><span class="type">int</span> <span class="title">epoll_create</span><span class="params">(<span class="type">int</span> size)</span></span>;</span><br><span class="line"><span class="number">2</span> <span class="function"><span class="type">int</span> <span class="title">epoll_create1</span><span class="params">(<span class="type">int</span> flags)</span></span>;</span><br><span class="line"><span class="number">3</span> 返回值: 若成功返回一个大于 <span class="number">0</span> 的值，表示 epoll 实例；若返回 <span class="number">-1</span> 表示出错</span><br></pre></td></tr></table></figure>

<p>如果这个 epoll 实例不再需要，比如服务器正常关机，需要调用 close() 方法释放 epoll 实例，这样系统内核可以回收 epoll 实例所分配使用的内核资源。</p>
<p>关于这个参数 size，在一开始的 epoll_create 实现中，是用来告知内核期望监控的文件描述字大小，然后内核使用这部分的信息来初始化内核数据结构，在新的实现中，这个参数不再被需要，因为内核可以动态分配需要的内核数据结构。我们只需要注意，每次将 size 设置成一个大于 0 的整数就可以了。</p>
<h4 id="4-4-3-epoll-ctl"><a href="#4-4-3-epoll-ctl" class="headerlink" title="4.4.3 epoll_ctl"></a>4.4.3 <strong>epoll_ctl</strong></h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> <span class="function"><span class="type">int</span> <span class="title">epoll_ctl</span><span class="params">(<span class="type">int</span> epfd, <span class="type">int</span> op, <span class="type">int</span> fd, <span class="keyword">struct</span> epoll_event *event)</span></span>;</span><br><span class="line"><span class="number">2</span> 返回值: 若成功返回 <span class="number">0</span>；若返回 <span class="number">-1</span> 表示出错</span><br></pre></td></tr></table></figure>

<p>第一个参数 epfd 是刚刚调用 epoll_create 创建的 epoll 实例描述字，可以简单理解成是 epoll 句柄。</p>
<p>第二个参数表示增加还是删除一个监控事件，它有三个选项可供选择：</p>
<ol>
<li><strong>EPOLL_CTL_ADD： 向 epoll 实例注册文件描述符对应的事件；</strong></li>
<li><strong>EPOLL_CTL_DEL：向 epoll 实例删除文件描述符对应的事件；</strong></li>
<li><strong>EPOLL_CTL_MOD： 修改文件描述符对应的事件。</strong></li>
</ol>
<p>第三个参数是注册的事件的文件描述符，比如一个监听套接字。</p>
<p>第四个参数表示的是注册的事件类型，并且可以在这个结构体里设置用户需要的数据，其中最为常见的是使用联合结构里的 fd 字段，表示事件所对应的文件描述符。</p>
<p>我们在前面介绍 poll 的时候已经接触过基于 mask 的事件类型了，这里 epoll 仍旧使用了同样的机制，我们重点看一下这几种事件类型：</p>
<ol>
<li><strong>EPOLLIN：表示对应的文件描述字可以读；</strong></li>
<li><strong>EPOLLOUT：表示对应的文件描述字可以写；</strong></li>
<li><strong>EPOLLRDHUP：表示套接字的一端已经关闭，或者半关闭；</strong></li>
<li><strong>EPOLLHUP：表示对应的文件描述字被挂起；</strong></li>
<li><strong>EPOLLET：设置为 edge-triggered，默认为 level-triggered。</strong></li>
</ol>
<p><em><strong><u>代码详见PPT</u></strong></em></p>
<h3 id="4-5-C10K问题：高并发模型设计"><a href="#4-5-C10K问题：高并发模型设计" class="headerlink" title="4.5  C10K问题：高并发模型设计"></a>4.5  C10K问题：高并发模型设计</h3><h4 id="4-5-1-C10K-问题"><a href="#4-5-1-C10K-问题" class="headerlink" title="4.5.1 C10K 问题"></a>4.5.1 <strong>C10K</strong> <strong>问题</strong></h4><p>C10K 问题是这样的：<strong>如何在一台物理机上同时服务 10000 个用户？</strong>这里 C 表示并发，10K 等于 10000。得益于操作系统、编程语言的发展，在现在的条件下，普通用户使用 Java Netty、Libevent 等框架或库就可以轻轻松松写出支持并发超过 10000 的服务器端程序，甚至于经过优化之后可以达到十万，乃至百万的并发，但在二十年前，突破 C10K 问题可费了不少的心思，是一个了不起的突破。</p>
<h4 id="4-5-2-操作系统层面"><a href="#4-5-2-操作系统层面" class="headerlink" title="4.5.2 操作系统层面"></a>4.5.2 <strong>操作系统层面</strong></h4><p>C10K 问题本质上是一个操作系统问题，要在一台主机上同时支持 1 万个连接，意味着什么呢? 需要考虑哪些方面？</p>
<p>（1）<strong>文件句柄</strong></p>
<p>我们知道每个客户连接都代表一个文件描述符，一旦文件描述符不够用了，新的连接就会被放弃。</p>
<p><strong>在 Linux 下，单个进程打开的文件句柄数是有限制的，没有经过修改的值一般都是 1024。</strong></p>
<p>这意味着最多可以服务的连接数上限只能是 1024。不过，我们可以对这个值进行修改，比如用 root 权限修改 /etc/sysctl.conf 文件，使得系统可用支持 10000 个描述符上限。</p>
<p>（2）<strong>系统内存</strong></p>
<p>每个 TCP 连接占用的资源可不止一个连接套接字这么简单，在前面的章节中，我们多少接触到了类似发送缓冲区、接收缓冲区这些概念。每个 TCP 连接都需要占用一定的发送缓冲区和接收缓冲区。</p>
<p>我在文稿里放了一段 shell 代码，分别显示了在 Linux 4.4.0 下发送缓冲区和接收缓冲区的值。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$</span><span class="language-bash"><span class="built_in">cat</span> /proc/sys/net/ipv4/tcp_wmem</span></span><br><span class="line">4096 16384 4194304</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> /proc/sys/net/ipv4/tcp_rmem</span></span><br><span class="line">4096 87380 6291456</span><br></pre></td></tr></table></figure>

<p>这三个值分别表示了最小分配值、默认分配值和最大分配值。按照默认分配值计算，一万个连接需要的内存消耗为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">发送缓冲区： 16384*10000/8 = 20M bytes</span><br><span class="line">接收缓冲区： 87380*10000/8 = 110M bytes</span><br></pre></td></tr></table></figure>

<p>当然，我们的应用程序本身也需要一定的缓冲区来进行数据的收发，为了方便，我们假设每个连接需要 128K 的缓冲区，那么 1 万个链接就需要大约 1.2G 的应用层缓冲。这样，我们可以得出大致的结论，支持 1 万个并发连接，内存并不是一个巨大的瓶颈。</p>
<p>（3）<strong>网络带宽</strong></p>
<p>假设 1 万个连接，每个连接每秒传输大约 1KB 的数据，那么带宽需要 10000 x 1KB/s x8 = 80Mbps。这在今天的动辄万兆网卡的时代简直小菜一碟。</p>
<h4 id="4-5-3-C10K-问题解决之道"><a href="#4-5-3-C10K-问题解决之道" class="headerlink" title="4.5.3 C10K 问题解决之道"></a>4.5.3 <strong>C10K</strong> <strong>问题解决之道</strong></h4><p>但是，能解决并不意味着可以很好地解决。我们知道，在网络编程中，涉及到频繁的用户态——内核态数据拷贝，设计不够好的程序可能在低并发的情况下工作良好，一旦到了高并发情形，其性能可能呈现出指数级别的损失。</p>
<p>举一个例子，如果没有考虑好 C10K 问题，一个基于 select 的经典程序可能在一台服务器上可以很好处理 1000 的并发用户，但是在性能 2 倍的服务器上，却往往并不能很好地处理 2000 的并发用户。</p>
<p>要想解决 C10K 问题，就需要从两个层面上来统筹考虑。</p>
<ol>
<li><strong>第一个层面，应用程序如何和操作系统配合，感知 I/O 事件发生，并调度处理在上万个套接字上的 I/O 操作？前面讲过的阻塞 I/O、非阻塞 I/O 讨论的就是这方面的问题。</strong></li>
<li><strong>第二个层面，应用程序如何分配进程、线程资源来服务上万个连接？这在接下来会详细讨论。</strong></li>
</ol>
<p>（1）<strong>阻塞</strong> <strong>I/O +</strong> <strong>进程</strong></p>
<p>（2）<strong>阻塞</strong> <strong>I/O +</strong> <strong>线程</strong></p>
<p>因为线程的创建是比较消耗资源的，况且不是每个连接在每个时刻都需要服务，因此，我们可以预先通过创建一个线程池，并在多个连接中复用线程池来获得某种效率上的提升。</p>
<p>（3）<strong>非阻塞</strong> <strong>I/O + readiness notification +</strong> <strong>单线程</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> <span class="keyword">for</span> fd in fdset&#123;</span><br><span class="line"><span class="number">2</span> 	<span class="keyword">if</span>(<span class="built_in">is_readable</span>(fd) == <span class="literal">true</span>)&#123;</span><br><span class="line"><span class="number">3</span> 		<span class="built_in">handle_read</span>(fd)</span><br><span class="line"><span class="number">4</span> 	&#125;<span class="keyword">else</span> <span class="keyword">if</span>(<span class="built_in">is_writeable</span>(fd)==<span class="literal">true</span>)&#123;</span><br><span class="line"><span class="number">5</span> 		<span class="built_in">handle_write</span>(fd)</span><br><span class="line"><span class="number">6</span> 	&#125;</span><br><span class="line"><span class="number">7</span> &#125;</span><br></pre></td></tr></table></figure>

<p>但这个方法有一个问题，如果这个 fdset 有一万个之多，每次循环判断都会消耗大量的 CPU 时间，而且极有可能在一个循环之内，没有任何一个套接字准备好可读，或者可写。</p>
<p>既然这样，CPU 的消耗太大，那么干脆让操作系统来告诉我们哪个套接字可以读，哪个套接字可以写。在这个结果发生之前，<strong>我们把 CPU 的控制权交出去，让操作系统来把宝贵的 CPU 时间调度给那些需要的进程，这就是 select、poll 这样的 I/O 分发技术。</strong></p>
<p>于是，程序就长成了这样：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> <span class="keyword">do</span> &#123;</span><br><span class="line"><span class="number">2</span> 	poller.<span class="built_in">dispatch</span>()</span><br><span class="line"><span class="number">3</span> 	<span class="keyword">for</span> fd in registered_fdset&#123;</span><br><span class="line"><span class="number">4</span> 		<span class="keyword">if</span>(<span class="built_in">is_readable</span>(fd) == <span class="literal">true</span>)&#123;</span><br><span class="line"><span class="number">5</span> 			<span class="built_in">handle_read</span>(fd)</span><br><span class="line"><span class="number">6</span> 		&#125;<span class="keyword">else</span> <span class="keyword">if</span>(<span class="built_in">is_writeable</span>(fd)==<span class="literal">true</span>)&#123;</span><br><span class="line"><span class="number">7</span> 			<span class="built_in">handle_write</span>(fd)</span><br><span class="line"><span class="number">8</span> 	&#125;</span><br><span class="line"><span class="number">9</span> &#125;<span class="keyword">while</span>(ture)</span><br></pre></td></tr></table></figure>

<p>（4）<strong>非阻塞</strong> <strong>I/O + readiness notification +</strong> <strong>多线程</strong></p>
<p>前面的做法是所有的 I/O 事件都在一个线程里分发，如果我们把线程引入进来，可以利用现代 CPU 多核的能力，让每个核都可以作为一个 I/O 分发器进行 I/O 事件的分发。</p>
<p>这就是所谓的主从 reactor 模式。基于 epoll/poll/select 的 I/O 事件分发器可以叫做 reactor，也可以叫做事件驱动，或者事件轮询（eventloop）。</p>
<p>（5）<strong>异步</strong> <strong>I/O+</strong> <strong>多线程</strong></p>
<p>异步非阻塞 I/O 模型是一种更为高效的方式，当调用结束之后，请求立即返回，由操作系统后台完成对应的操作，当最终操作完成，就会产生一个信号，或者执行一个回调函数来完成 I/O 处理。</p>
<p>4.5.4 <strong>总结</strong></p>
<p>支持单机 1 万并发的问题被称为 C10K 问题，为了解决 C10K 问题，需要重点考虑两个方面的问题：</p>
<ol>
<li><strong>如何和操作系统配合，感知 I/O 事件的发生？</strong></li>
<li><strong>如何分配和使用进程、线程资源来服务上万个连接？</strong></li>
</ol>
<p><em><strong><u>基于这些组合，产生了一些通用的解决方法，在 Linux 下，解决高性能问题的利器是非阻塞 I/O 加上 epoll 机制，再利用多线程能力。</u></strong></em></p>
<h3 id="4-6-I-O多路复用遇上线程：使用poll单线程处理所有I-O事件"><a href="#4-6-I-O多路复用遇上线程：使用poll单线程处理所有I-O事件" class="headerlink" title="4.6 I/O多路复用遇上线程：使用poll单线程处理所有I/O事件"></a>4.6 <strong>I/O多路复用遇上线程：使用poll单线程处理所有I/O事件</strong></h3><p>我在前面两讲里，分别使用了 fork 进程和 pthread 线程来处理多并发，这两种技术使用简单，但是性能却会随着并发数的上涨而快速下降，并不能满足极端高并发的需求。就像第 24 讲中讲到的一样，这个时候我们需要寻找更好的解决之道，这个解决之道基本的思想就是 I/O 事件分发。</p>
<h4 id="4-6-1-重温事件驱动"><a href="#4-6-1-重温事件驱动" class="headerlink" title="4.6.1 重温事件驱动"></a>4.6.1 <strong>重温事件驱动</strong></h4><p>一个无限循环的事件分发线程在后台运行，一旦用户在界面上产生了某种操作，例如点击了某个 Button，或者点击了某个文本框，一个事件会被产生并放置到事件队列中，这个事件会有一个类似前面的 onButtonClick 回调函数。事件分发线程的任务，就是为每个发生的事件找到对应的事件回调函数并执行它。这样，一个基于事件驱动的 GUI 程序就可以完美地工作了。</p>
<p>事件驱动模型，也被叫做反应堆模型（reactor），或者是 Event loop 模型。这个模型的核心有两点。</p>
<ol>
<li><strong>第一，它存在一个无限循环的事件分发线程，或者叫做 reactor 线程、Event loop 线程。这个事件分发线程的背后，就是 poll、epoll 等 I/O 分发技术的使用。</strong></li>
<li><strong>第二，所有的 I/O 操作都可以抽象成事件，每个事件必须有回调函数来处理。acceptor 上有连接建立成功、已连接套接字上发送缓冲区空出可以写、通信管道 pipe 上有数据可以读，这些都是一个个事件，通过事件分发，这些事件都可以一一被检测，并调用对应的回调函数加以处理。</strong></li>
</ol>
<h4 id="4-6-2-几种-I-O-模型和线程模型设计"><a href="#4-6-2-几种-I-O-模型和线程模型设计" class="headerlink" title="4.6.2 几种 I/O 模型和线程模型设计"></a>4.6.2 <strong>几种</strong> <strong>I/O</strong> <strong>模型和线程模型设计</strong></h4><p>任何一个网络程序，所做的事情可以总结成下面几种：</p>
<ol>
<li><strong>read：从套接字收取数据；</strong></li>
<li><strong>decode：对收到的数据进行解析；</strong></li>
<li><strong>compute：根据解析之后的内容，进行计算和处理；</strong></li>
<li><strong>encode：将处理之后的结果，按照约定的格式进行编码；</strong></li>
<li><strong>send：最后，通过套接字把结果发送出去。</strong></li>
</ol>
<p>这几个过程和套接字最相关的是 read 和 send 这两种。接下来，我们总结一下已经学过的几种支持多并发的网络编程技术，引出我们今天的话题，使用 poll 单线程处理所有 I/O。</p>
<h4 id="4-6-3-fork"><a href="#4-6-3-fork" class="headerlink" title="4.6.3 fork"></a>4.6.3 <strong>fork</strong></h4><h4 id="4-6-4-pthread"><a href="#4-6-4-pthread" class="headerlink" title="4.6.4 pthread"></a>4.6.4 <strong>pthread</strong></h4><p>第 26 讲中，我们使用了 pthread_create 创建子线程，因为线程是比进程更轻量级的执行单位，所以它的效率相比 fork 的方式，有一定的提高。但是，每次创建一个线程的开销仍然是不小的，因此，引入了线程池的概念，预先创建出一个线程池，在每次新连接达到时，从线程池挑选出一个线程为之服务，很好地解决了线程创建的开销。但是，<strong>这个模式还是没有解决空闲连接占用资源的问题，如果一个连接在一定时间内没有数据交互，这个连接还是要占用一定的线程资源，直到这个连接消亡为止。</strong></p>
<p><img src="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/34.png" alt="34"></p>
<h4 id="4-6-5-single-reactor-thread"><a href="#4-6-5-single-reactor-thread" class="headerlink" title="4.6.5 single reactor thread"></a>4.6.5 single reactor thread</h4><p>我在文稿中放了一张图解释了这一讲的设计模式。一个 reactor 线程上同时负责分发 acceptor 的事件、已连接套接字的 I/O 事件。</p>
<p><img src="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/35.png" alt="35"></p>
<h4 id="4-6-6-single-reactor-thread-worker-threads"><a href="#4-6-6-single-reactor-thread-worker-threads" class="headerlink" title="4.6.6 single reactor thread + worker threads"></a>4.6.6 <strong>single reactor thread + worker threads</strong></h4><p>但是上述的设计模式有一个问题，<strong>和 I/O 事件处理相比，应用程序的业务逻辑处理是比较耗时的，比如 XML 文件的解析、数据库记录的查找、文件资料的读取和传输、计算型工作的处理等，这些工作相对而言比较独立，它们会拖慢整个反应堆模式的执行效率。</strong></p>
<p>所以，将这些 decode、compute、enode 型工作放置到另外的线程池中，和反应堆线程解耦，是一个比较明智的选择。我在文稿中放置了这样的一张图。反应堆线程只负责处理 I/O 相关的工作，业务逻辑相关的工作都被裁剪成一个一个的小任务，放到线程池里由空闲的线程来执行。当结果完成后，再交给反应堆线程，由反应堆线程通过套接字将结果发送出去。</p>
<p><img src="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/36.png" alt="36"></p>
<p><em><strong><u>代码详见PPT</u></strong></em></p>
<h3 id="4-7-I-O多路复用进阶：子线程使用poll处理连接I-O事件"><a href="#4-7-I-O多路复用进阶：子线程使用poll处理连接I-O事件" class="headerlink" title="4.7 I/O多路复用进阶：子线程使用poll处理连接I/O事件"></a>4.7 <strong>I/O多路复用进阶：子线程使用poll处理连接I/O事件</strong></h3><p>我们仔细想想这种模式，在发起连接请求的客户端非常多的情况下，<strong>有一个地方是有问题的，那就是单 reactor 线程既分发连接建立，又分发已建立连接的 I/O，有点忙不过来，在实战中的表现可能就是客户端连接成功率偏低。</strong></p>
<p>再者，新的硬件技术不断发展，多核多路 CPU 已经得到极大的应用，单 reactor 反应堆模式看着大把的 CPU 资源却不用，有点可惜。</p>
<h4 id="4-7-1-主-从-reactor-模式"><a href="#4-7-1-主-从-reactor-模式" class="headerlink" title="4.7.1 主 - 从 reactor 模式"></a>4.7.1 <strong>主</strong> <strong>-</strong> <strong>从</strong> <strong>reactor</strong> <strong>模式</strong></h4><p>主 - 从这个模式的核心思想是，主反应堆线程只负责分发 Acceptor 连接建立，已连接套接 字上的 I/O 事件交给 sub-reactor 负责分发。其中 sub-reactor 的数量，可以根据 CPU 的核数来灵活设置。</p>
<p>比如一个四核 CPU，<strong>我们可以设置 sub-reactor 为 4。相当于有 4 个身手不凡的反应堆线程同时在工作，这大大增强了 I/O 分发处理的效率。而且，同一个套接字事件分发只会出现在一个反应堆线程中，这会大大减少并发处理的锁开销。</strong></p>
<p><img src="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/37.png" alt="37"></p>
<p>我来解释一下这张图，我们的主反应堆线程一直在感知连接建立的事件，如果有连接成功建立，主反应堆线程通过 accept 方法获取已连接套接字，接下来会按照一定的算法选取一个从反应堆线程，并把已连接套接字加入到选择好的从反应堆线程中。</p>
<p>主反应堆线程唯一的工作，就是调用 accept 获取已连接套接字，以及将已连接套接字加入到从反应堆线程中。不过，这里还有一个小问题，<strong>主反应堆线程和从反应堆线程，是两个不同的线程，如何把已连接套接字加入到另外一个线程中呢？更令人沮丧的是，此时从反应堆线程或许处于事件分发的无限循环之中，在这种情况下应该怎么办呢？</strong>我在这里先卖个关子，这是高性能网络程序框架要解决的问题。在实战篇里，我将为这些问题一一解开答案。</p>
<h4 id="4-7-2-主-从-reactor-worker-threads-模式"><a href="#4-7-2-主-从-reactor-worker-threads-模式" class="headerlink" title="4.7.2 主 - 从 reactor+worker threads 模式"></a>4.7.2 主 - 从 reactor+worker threads 模式</h4><p>如果说主 - 从 reactor 模式解决了 I/O 分发的高效率问题，那么 work threads 就解决了业务逻辑和 I/O 分发之间的耦合问题。把这两个策略组装在一起，就是实战中普遍采用的模式。大名鼎鼎的 Netty，就是把这种模式发挥到极致的一种实现。不过要注意 Netty 里面提到的 worker 线程，其实就是我们这里说的从 reactor 线程，并不是处理具体业务逻辑的 worker 线程。</p>
<p>下面贴的一段代码就是常见的 Netty 初始化代码，这里 Boss Group 就是 acceptor 主反应堆，workerGroup 就是从反应堆。而处理业务逻辑的线程，通常都是通过使用 Netty 的程序开发者进行设计和定制，<strong>一般来说，业务逻辑线程需要从 workerGroup 线程中分离，以便支持更高的并发度。</strong></p>
<h3 id="4-8-渐入佳境：使用epoll和多线程模型"><a href="#4-8-渐入佳境：使用epoll和多线程模型" class="headerlink" title="4.8 渐入佳境：使用epoll和多线程模型"></a>4.8 <strong>渐入佳境：使用epoll和多线程模型</strong></h3><p><strong>epoll</strong> <strong>的性能分析</strong></p>
<p>epoll 的性能凭什么就要比 poll 或者 select 好呢？这要从两个角度来说明。</p>
<ol>
<li>第一个角度是事件集合。<strong>在每次使用 poll 或 select 之前，都需要准备一个感兴趣的事件集合</strong>，系统内核拿到事件集合，进行分析并在内核空间构建相应的数据结构来完成对事件集合的注册。而 epoll 则不是这样，<strong>epoll 维护了一个全局的事件集合</strong>，通过 epoll 句柄，可以操纵这个事件集合，增加、删除或修改这个事件集合里的某个元素。要知道在绝大多数情况下，事件集合的变化没有那么的大，<strong>这样操纵系统内核就不需要每次重新扫描事件集合，构建内核空间数据结构。</strong></li>
<li>第二个角度是就绪列表。每次在使用 poll 或者 select 之后，应用程序都需要扫描整个感兴趣的事件集合，从中找出真正活动的事件，<strong>这个列表如果增长到 10K 以上，每次扫描的时间损耗也是惊人的。</strong>事实上，很多情况下扫描完一圈，可能发现只有几个真正活动的事件。<strong>而 epoll 则不是这样，epoll 返回的直接就是活动的事件列表，应用程序减少了大量的扫描时间。</strong></li>
</ol>
<p>此外， epoll 还提供了更高级的能力——边缘触发。第 23 讲通过一个直观的例子，讲解了边缘触发和条件触发的区别。这里再举一个例子说明一下。</p>
<p>如果某个套接字有 100 个字节可以读，边缘触发和条件触发都会产生 read ready notification 事件，如果应用程序只读取了 50 个字节，边缘触发就会陷入等待；而条件触发则会因为还有 50 个字节没有读取完，不断地产生 read ready notification 事件。</p>
<p>在边缘触发下，如果某个套接字缓冲区可以写，会无限次返回 write ready notification 事件，在这种情况下，如果应用程序没有准备好，不需要发送数据，一定需要解除套接字上的 ready notification 事件，否则 CPU 就直接跪了。</p>
<p><strong>我们简单地总结一下，边缘触发只会产生一次活动事件，性能和效率更高。不过，程序处理起来要更为小心。</strong></p>
<h3 id="4-9-真正的大杀器：异步I-O探索"><a href="#4-9-真正的大杀器：异步I-O探索" class="headerlink" title="4.9 真正的大杀器：异步I/O探索"></a>4.9 <strong>真正的大杀器：异步I/O探索</strong></h3><p>在性能篇的前几讲中，我们谈到了阻塞 I/O、非阻塞 I/O 以及像 select、poll、epoll 等 I/O 多路复用技术，并在此基础上结合线程技术，实现了以事件分发为核心的 reactor 反应堆模式。你或许还听说过一个叫做 Proactor 的网络事件驱动模式，<strong>这个 Proactor 模式和 reactor 模式到底有什么区别和联系呢？</strong>在今天的内容中，我们先讲述异步 I/O，再一起揭开以异步 I/O 为基础的 proactor 模式的面纱。</p>
<h4 id="4-9-1-阻塞-非阻塞-VS-同步-异步"><a href="#4-9-1-阻塞-非阻塞-VS-同步-异步" class="headerlink" title="4.9.1 阻塞 / 非阻塞 VS 同步 / 异步"></a>4.9.1 <strong>阻塞</strong> <strong>/</strong> <strong>非阻塞</strong> <strong>VS</strong> <strong>同步</strong> <strong>/</strong> <strong>异步</strong></h4><p>第一种是阻塞 I/O。阻塞 I/O 发起的 read 请求，线程会被挂起，一直等到内核数据准备好，并把数据从内核区域拷贝到应用程序的缓冲区中，当拷贝过程完成，read 请求调用才返回。接下来，应用程序就可以对缓冲区的数据进行数据解析。</p>
<p>第二种是非阻塞 I/O。非阻塞的 read 请求在数据未准备好的情况下立即返回，应用程序可以不断轮询内核，直到数据准备好，内核将数据拷贝到应用程序缓冲，并完成这次 read 调用。注意，这里最后一次 read 调用，获取数据的过程，<strong>是一个同步的过程。这里的同步指的是内核区域的数据拷贝到缓存区这个过程。</strong></p>
<p><img src="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/38.png"></p>
<p>每次让应用程序去轮询内核的 I/O 是否准备好，是一个不经济的做法，<strong>因为在轮询的过程中应用进程啥也不能干。于是，像 select、poll 这样的 I/O 多路复用技术就隆重登场了。通过 I/O 事件分发，当内核数据准备好时，再通知应用程序进行操作。这个做法大大改善了应用进程对 CPU 的利用率</strong>，在没有被通知的情况下，应用进程可以使用 CPU 做其他的事情。</p>
<p>注意，这里 read 调用，获取数据的过程，<strong>也是一个同步的过程。</strong></p>
<p><img src="https://yygh-testosscjf.oss-cn-beijing.aliyuncs.com/39.png" alt="39"></p>
<p>第一种阻塞 I/O 我想你已经比较了解了，在阻塞 I/O 的情况下，应用程序会被挂起，直到获取数据。第二种非阻塞 I/O 和第三种基于非阻塞 I/O 的多路复用技术，获取数据的操作不会被阻塞。</p>
<p>无论是第一种阻塞 I/O，还是第二种非阻塞 I/O，第三种基于非阻塞 I/O 的多路复用都是<strong>同步调用技术。为什么这么说呢？因为同步调用、异步调用的说法，是对于获取数据的过程而言的，前面几种最后获取数据的 read 操作调用，都是同步的，在 read 调用时，内核将数据从内核空间拷贝到应用程序空间，这个过程是在 read 函数中同步进行的，如果内核实现的拷贝效率很差，read 调用就会在这个同步过程中消耗比较长的时间。</strong></p>
<p>而真正的异步调用则不用担心这个问题，我们接下来就来介绍第四种 I/O 技术，当我们发起 aio_read 之后，就立即返回，内核自动将数据从内核空间拷贝到应用程序空间，这个拷贝过程是异步的，内核自动完成的，和前面的同步操作不一样，应用程序并不需要主动发起拷贝动作。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://nannaer.github.io/2023/04/24/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/" data-id="clhaexqgw0004dwv7bprs9si3" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/04/27/TCP/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          (no title)
        
      </div>
    </a>
  
  
    <a href="/2023/04/20/%E5%86%85%E5%AD%98/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title"></div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/04/">April 2023</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/04/27/TCP/">(no title)</a>
          </li>
        
          <li>
            <a href="/2023/04/24/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/">(no title)</a>
          </li>
        
          <li>
            <a href="/2023/04/20/%E5%86%85%E5%AD%98/">(no title)</a>
          </li>
        
          <li>
            <a href="/2023/04/17/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/">(no title)</a>
          </li>
        
          <li>
            <a href="/2023/04/15/JUC/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>